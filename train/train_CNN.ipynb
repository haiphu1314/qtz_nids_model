{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usami/miniconda3/envs/human_action/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/usami/miniconda3/envs/human_action/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c107WarningC1ENS_7variantIJNS0_11UserWarningENS0_18DeprecationWarningEEEERKNS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# modified from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117611/2989520626.py:13: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_bot_dos = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/datasetv2/train/bot_iot_dos.csv')\n",
      "/tmp/ipykernel_117611/2989520626.py:14: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_bot_ddos = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/datasetv2/train/bot_iot_ddos.csv')\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# df_unsw_normal = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/dataset/train/unsw_normal.csv')\n",
    "df_bot_dos = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/datasetv2/train/bot_iot_dos.csv')\n",
    "df_bot_ddos = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/datasetv2/train/bot_iot_ddos.csv')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_bot_dos, df_bot_ddos], ignore_index=True)\n",
    "df_combined['sport'] = np.where(df_combined['sport'] == '0x0303', 0x0303, df_combined['sport'])\n",
    "df_combined['sport'] = np.where(df_combined['sport'] == '0x5000', 0x5000, df_combined['sport'])\n",
    "df_combined = df_combined[(df_combined['state']=='INT') | (df_combined['state']=='REQ')| (df_combined['state']=='RST')| (df_combined['state']=='ACC')| (df_combined['state']=='CON')| (df_combined['state']=='FIN')]\n",
    "df_combined['flgs'] = df_combined['flgs'].map({'e': 0, 'e s': 1, 'e g': 2, 'eU': 3, 'e *':4, 'e d':5})\n",
    "df_combined['state'] = df_combined['state'].map({'INT': 0, 'REQ': 1, 'RST': 2, 'ACC': 3, 'CON':4, 'FIN':6})\n",
    "\n",
    "x = df_combined.loc[:, df_combined.columns != 'category']\n",
    "x_ = np.zeros((x.shape[0], 49))\n",
    "x_[:, :43] = x\n",
    "x = x_\n",
    "\n",
    "# x = (x-x.min())/(x.max()-x.min())\n",
    "\n",
    "df_combined.category = pd.factorize(df_combined.category)[0]\n",
    "y = df_combined['category']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "# for i in [0,1,2,3,7,8]:\n",
    "#     x[:,i] = np.where(x[:,i] > 0, np.log(x[:,i]), 0)\n",
    "x = x.reshape(x.shape[0], 1, 7, 7)    \n",
    "x_label_data = torch.tensor(x, dtype=torch.float).to(device)\n",
    "y_label_data = torch.tensor(y, dtype=torch.long).to(device)\n",
    "\n",
    "dataset = TensorDataset(x_label_data, y_label_data)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.25 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8192\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Validation Accuracy: 50.00%4\n",
      "Epoch [2/2], Validation Accuracy: 100.00%\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "quant = 'TNN'\n",
    "class Netb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netb, self).__init__()\n",
    "        # self.fc0 = QLinear(7 * 7, 64 * 64, bias=False)\n",
    "        self.conv1 = QConv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1, bias=False, quant=quant)\n",
    "        self.conv2 = QConv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, bias=False, quant=quant)\n",
    "        self.linear1 = QLinear(64 * 7 * 7, 128, bias=False, quant=quant)\n",
    "        self.linear2 = QLinear(128, 3, bias=False, quant=quant)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_b = Netb().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_b.parameters(), 0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model_b.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_b(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # model_ter1.set_weights_and_biases()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}', end='\\r')\n",
    "    \n",
    "    model_b.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_b(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Final evaluation on the test set\n",
    "model_b.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_b(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "torch.save(model_b.state_dict(), 'saved_best_model_bcnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_model_parameters_to_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_model_parameters_to_txt\u001b[49m(model_b, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtcnn_model_parameters.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_model_parameters_to_txt' is not defined"
     ]
    }
   ],
   "source": [
    "class Netb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netb, self).__init__()\n",
    "        # self.fc0 = QLinear(7 * 7, 64 * 64, bias=False)\n",
    "        self.conv1 = QConv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1, bias=False, quant=quant)\n",
    "        self.conv2 = QConv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, bias=False, quant=quant)\n",
    "        self.linear1 = QLinear(64 * 7 * 7, 128, bias=False, quant=quant)\n",
    "        self.linear2 = QLinear(128, 3, bias=False, quant=quant)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x = self.conv2(x1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        x = self.act4(x)\n",
    "        return x1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_b = Netb().to(device)\n",
    "model_b.load_state_dict(torch.load('saved_best_model_bcnn.pt'))\n",
    "save_model_parameters_to_txt(model_b, 'tcnn_model_parameters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ternary(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ternary, self).__init__()\n",
    "        config = {}\n",
    "        self.config = config\n",
    "        self.delta = config.setdefault(\"delta\", 0.5)\n",
    "        self.momentum = config.setdefault(\"momentum\", 0.01)\n",
    "        self.track_running_stats = config.setdefault(\"track_running_stats\", True)\n",
    "        self.order = config.setdefault('order', 2)\n",
    "        # self.use_scale = config.setdefault('use_scale', True)\n",
    "        assert self.momentum <= 1 and self.order > 0 and self.delta > 0\n",
    "        self.register_buffer(\"running_delta\", torch.zeros(1))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.momentum > 0:\n",
    "            self.running_delta.fill_(self.delta * 0.7979)\n",
    "        else:\n",
    "            self.running_delta.fill_(self.delta)\n",
    "\n",
    "    def forward(self, input_f):\n",
    "        return ternary(input_f, self.running_delta, self.delta, self.momentum,\n",
    "                       self.training and self.track_running_stats, self.order)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \", \".join([\"{}={}\".format(k, v) for k, v in self.config.items()])\n",
    "\n",
    "class QConv2d(torch.nn.Conv2d):\n",
    "    qa_config = {}\n",
    "    qw_config = {}\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False,\n",
    "                 padding_mode='zeros', quant = 'BNN'):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\n",
    "        \n",
    "        if quant == 'BNN':\n",
    "            self.input_quantizer = BinaryActivation()\n",
    "            self.weight_quantizer = BinaryActivation()\n",
    "        elif quant == 'TNN':\n",
    "            self.input_quantizer = Ternary()\n",
    "            self.weight_quantizer = Ternary()\n",
    "        elif quant == 'TBN':\n",
    "            self.input_quantizer = Ternary()\n",
    "            self.weight_quantizer = BinaryActivation()\n",
    "        self.i = 0\n",
    "\n",
    "    def forward(self, input_f):\n",
    "        input_t = self.input_quantizer(input_f)\n",
    "        weight_b = self.weight_quantizer(self.weight)\n",
    "        out = F.conv2d(input_t, weight_b, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        if(self.i == 0):\n",
    "            self.i = 1\n",
    "            # print(input_t)\n",
    "            print(self.weight)\n",
    "            print(weight_b)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Netb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netb, self).__init__()\n",
    "        # self.fc0 = QLinear(7 * 7, 64 * 64, bias=False)\n",
    "        self.conv1 = QConv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1, bias=False, quant=quant)\n",
    "        self.conv2 = QConv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, bias=False, quant=quant)\n",
    "        self.linear1 = QLinear(64 * 7 * 7, 128, bias=False, quant=quant)\n",
    "        self.linear2 = QLinear(128, 3, bias=False, quant=quant)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        print(\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\")\n",
    "        x1 = self.conv1(x)\n",
    "        print(\"BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\")\n",
    "        print(x1)\n",
    "        x = self.conv2(x1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        x = self.act4(x)\n",
    "        return x1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_b = Netb().to(device)\n",
    "model_b.load_state_dict(torch.load('saved_best_model_bcnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  1.,  1.],\n",
       "          [ 0., -1., -1.],\n",
       "          [ 1.,  1.,  1.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = name.split('.')[0]\n",
    "getattr(getattr(model_b, nn).weight_quantizer, 'forward')(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linear2'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = name.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv2.weight\n",
      "linear1.weight\n",
      "linear2.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_b.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "Parameter containing:\n",
      "tensor([[[[ 2.2384e-01,  2.2946e-01,  2.7293e-01],\n",
      "          [-9.5651e-04, -2.6885e-01, -2.5753e-01],\n",
      "          [ 1.5774e-01,  1.4375e-01,  6.2775e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7201e-01, -3.0356e-01,  2.7134e-01],\n",
      "          [-4.3390e-02,  1.4793e-01,  1.4906e-01],\n",
      "          [ 4.0869e-01, -1.7056e-01, -2.2095e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4437e-01, -1.8334e-01, -2.1462e-01],\n",
      "          [ 2.9422e-01,  4.7742e-01,  8.8640e-01],\n",
      "          [-2.5724e-01,  2.4763e-01, -1.9743e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.3729e-01, -3.0430e-01, -3.1893e-01],\n",
      "          [-4.3160e-01,  2.2575e-01, -5.6895e-01],\n",
      "          [-4.7998e-02, -2.6802e-01, -8.5414e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.3040e-01, -2.5569e-01,  1.6291e-01],\n",
      "          [ 1.0130e-01, -1.9798e-01, -2.3457e-01],\n",
      "          [ 4.7315e-02,  2.8065e-01, -7.1974e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2168e-01,  2.4957e-01, -1.7423e-01],\n",
      "          [-2.8821e-01,  8.3267e-02, -3.2709e-01],\n",
      "          [ 2.8243e-01,  1.2911e-01, -2.6657e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5369e-01,  6.5130e-01,  4.1395e-01],\n",
      "          [-3.0483e-01,  3.2942e-01, -3.0655e-01],\n",
      "          [ 3.2622e-01, -4.0352e-01, -5.6392e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5243e-03,  2.4588e-01,  4.0350e-02],\n",
      "          [-2.0812e-01,  2.4641e-01,  2.3137e-01],\n",
      "          [ 1.2412e-01, -4.0625e-02,  8.6534e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8890e-01, -4.3219e-01, -1.0766e+00],\n",
      "          [ 6.9136e-01, -3.4737e-01,  2.1509e-01],\n",
      "          [-3.2395e-01,  2.4559e-01,  6.7190e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6704e-04, -1.5736e-01,  7.5594e-01],\n",
      "          [-3.2410e-01, -2.7281e-01,  2.2335e-01],\n",
      "          [-3.8025e-01, -2.6742e-01,  3.0619e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0097e-01, -2.5631e-01,  2.6483e-01],\n",
      "          [ 2.6394e-01, -2.5804e-01, -8.0675e-03],\n",
      "          [ 2.9984e-01, -7.5616e-02, -4.0549e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0280e-01, -2.0193e-01,  2.7382e-01],\n",
      "          [ 2.6613e-01, -2.5849e-01, -1.9345e+00],\n",
      "          [ 3.2329e-01, -2.7633e-01, -4.8165e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5099e-01, -2.6880e-01,  2.7130e-01],\n",
      "          [-2.8255e-01,  9.1935e-01, -5.9180e-03],\n",
      "          [ 2.3400e-01,  1.4861e-01,  1.6592e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.6231e-04,  2.7115e-01,  3.1996e-01],\n",
      "          [-2.7939e-01, -2.7252e-01,  2.8857e-01],\n",
      "          [ 2.1303e-01,  2.0316e-01, -4.4617e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5069e-01, -2.7645e-01, -2.5495e-01],\n",
      "          [ 3.2738e-01,  2.1655e-01, -1.5736e-01],\n",
      "          [ 6.7990e-02,  6.2676e-01,  6.6373e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6545e-01,  2.5991e-01,  2.9329e-01],\n",
      "          [-5.9127e-01,  2.1050e-01, -2.7656e-01],\n",
      "          [ 3.0206e-01,  1.1274e-01, -4.1250e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2719e-01, -7.2225e-01, -2.7552e-01],\n",
      "          [ 5.7175e-03, -3.7580e-01,  1.5014e-01],\n",
      "          [ 9.3449e-04, -2.3818e-01, -1.2727e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8943e-01,  2.8270e-01,  5.6072e-02],\n",
      "          [-1.3629e-01, -3.1980e-01, -2.8103e-01],\n",
      "          [ 2.3651e-01,  2.9135e-01, -1.7916e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3225e-02,  2.7018e-01,  4.4950e-01],\n",
      "          [-6.9819e-01, -9.3881e-02,  3.3286e-01],\n",
      "          [ 2.8709e-01, -1.9406e-01, -5.2635e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9002e-01, -3.0258e-03, -2.3074e-02],\n",
      "          [-1.8975e-01, -1.7533e-01,  1.5104e-01],\n",
      "          [ 2.2151e-01, -6.3582e-01, -2.9002e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4779e-01, -1.2406e-01, -2.3031e-01],\n",
      "          [-2.8373e-01,  1.5371e-01, -3.0812e-01],\n",
      "          [ 2.9658e-01, -9.9534e-02, -3.4029e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3085e-01, -2.3487e-01,  2.8189e-01],\n",
      "          [-3.3903e-01, -1.8038e-01, -2.6319e-01],\n",
      "          [ 2.2155e-01,  3.7524e-01, -2.6153e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1120e-01, -6.0533e-03, -1.6118e-01],\n",
      "          [-2.7198e-01, -2.6335e-01,  9.2882e-01],\n",
      "          [ 2.9719e-01,  1.5651e-01, -2.0623e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3265e-01, -8.9535e-02,  3.0907e-01],\n",
      "          [ 1.8578e-01, -2.8643e-01,  2.6292e-01],\n",
      "          [-2.5204e-02, -2.3164e-01, -2.1972e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2361e-01, -5.4247e-01, -2.7578e-01],\n",
      "          [-2.5149e-01,  2.2032e-01,  2.0326e-01],\n",
      "          [-3.2391e-01,  3.1960e-01,  3.5584e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2196e-02,  2.1249e-01,  2.5696e-01],\n",
      "          [ 2.7084e-01,  2.4867e-01,  2.1187e-01],\n",
      "          [-1.8707e-01,  6.2833e-01,  1.8989e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6757e-01, -5.1529e-01, -2.4353e-01],\n",
      "          [ 2.6488e-01,  4.0302e-01,  2.7264e-01],\n",
      "          [ 1.2835e-01,  3.1480e-01, -2.8174e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4413e-01, -5.5380e-01, -1.9826e-01],\n",
      "          [ 2.6536e-01,  2.6967e-01, -1.3370e-01],\n",
      "          [-3.1721e-01, -1.3163e-01,  3.1064e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6557e-02,  9.5948e-01,  2.0657e-01],\n",
      "          [-1.8933e-01,  3.1061e-01,  3.4915e-01],\n",
      "          [-3.1657e-01,  2.2791e-01, -2.9310e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6985e-01,  6.0079e-01, -2.5943e-01],\n",
      "          [ 2.8702e-01, -5.4185e-01,  3.1700e-01],\n",
      "          [-1.9499e-01,  3.1507e-02,  3.0105e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4794e-01,  2.2433e-01,  7.9008e-01],\n",
      "          [ 1.1296e+00,  4.4845e-01,  1.1651e-01],\n",
      "          [-2.3740e-01, -2.4891e-01, -3.3032e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3609e-01,  2.4975e-01,  2.3865e-01],\n",
      "          [-2.9519e-01,  2.6365e-01, -1.3488e-01],\n",
      "          [ 1.2022e-01, -1.4573e-01, -3.0155e-01]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[[[ 1.,  1.,  1.],\n",
      "          [ 0., -1., -1.],\n",
      "          [ 1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1.,  1.],\n",
      "          [ 0.,  1.,  1.],\n",
      "          [ 1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1., -1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [-1.,  1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [ 0., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1.,  1.],\n",
      "          [ 0., -1., -1.],\n",
      "          [ 0.,  1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  1., -1.],\n",
      "          [-1.,  0., -1.],\n",
      "          [ 1.,  0., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [ 1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  1.,  0.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 0.,  0.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1., -1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [-1.,  1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0., -1.,  1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [-1., -1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1.,  1.],\n",
      "          [ 1., -1.,  0.],\n",
      "          [ 1.,  0., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1.,  1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1.,  1.],\n",
      "          [-1.,  1.,  0.],\n",
      "          [ 1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  1.,  1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1.,  1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.],\n",
      "          [ 1.,  1., -1.],\n",
      "          [ 0.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [ 1.,  0., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.],\n",
      "          [ 0., -1.,  1.],\n",
      "          [ 0., -1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  0.],\n",
      "          [ 0., -1., -1.],\n",
      "          [ 1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  1.,  1.],\n",
      "          [-1.,  0.,  1.],\n",
      "          [ 1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  0.,  0.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  0., -1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [ 1.,  0., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  0., -1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [ 0., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1., -1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [ 0.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1., -1.],\n",
      "          [ 1.,  1.,  0.],\n",
      "          [-1.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  1.,  1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1., -1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [-1.,  0.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  1.],\n",
      "          [ 1.,  1.,  0.],\n",
      "          [-1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1.,  1.],\n",
      "          [-1.,  1.,  0.],\n",
      "          [ 0., -1., -1.]]]], device='cuda:0', grad_fn=<_ternary_pyBackward>)\n",
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
      "tensor([[[[ 0.,  1., -1.,  ..., -1.,  1., -1.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          ...,\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          [ 0.,  1., -1.,  ..., -1.,  1., -1.]],\n",
      "\n",
      "         [[ 0.,  1., -1.,  ..., -1.,  1., -1.],\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          ...,\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          [-2.,  3., -3.,  ..., -3.,  3., -1.]],\n",
      "\n",
      "         [[ 1., -1.,  1.,  ...,  1., -1.,  2.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -2.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.,  3., -3.,  ..., -3.,  3., -1.],\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          ...,\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 1., -1.,  1.,  ...,  1., -1.,  0.],\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          ...,\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  2.]],\n",
      "\n",
      "         [[ 1., -2.,  2.,  ...,  2., -2.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          ...,\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  2.]]]], device='cuda:0',\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.2261e-03, -5.0895e-02,  4.7574e-02],\n",
      "          [-5.6012e-02,  2.2410e-02, -1.9850e-03],\n",
      "          [ 2.3949e-03, -4.8149e-03,  6.4186e-02]],\n",
      "\n",
      "         [[ 4.1882e-02, -5.6124e-02,  2.5328e-03],\n",
      "          [-5.8204e-02, -3.6482e-02, -4.6972e-02],\n",
      "          [-2.6420e-02, -4.3066e-02, -3.1011e-02]],\n",
      "\n",
      "         [[ 3.5761e-02,  4.0774e-02,  1.4294e-02],\n",
      "          [ 1.7810e-02, -2.5733e-02, -4.3966e-02],\n",
      "          [ 1.7685e-02, -1.2772e-02, -5.8158e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.9482e-03, -4.1478e-02,  2.3330e-02],\n",
      "          [-1.8408e-02, -5.8509e-02,  1.3930e-02],\n",
      "          [-3.3617e-02, -4.1382e-03,  2.0730e-03]],\n",
      "\n",
      "         [[-2.7635e-02, -4.0778e-02,  1.0692e-02],\n",
      "          [-2.2010e-02, -5.7329e-02,  4.5885e-02],\n",
      "          [ 3.8183e-02,  6.8794e-02,  1.0223e-02]],\n",
      "\n",
      "         [[-7.1052e-05, -9.3283e-03,  1.6465e-02],\n",
      "          [-5.4625e-02,  3.2046e-02,  3.7009e-02],\n",
      "          [-8.0056e-04, -2.7785e-02, -3.1864e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.6236e-02,  3.2165e-02,  3.0002e-02],\n",
      "          [-5.0317e-02, -8.9126e-02, -4.2363e-02],\n",
      "          [-3.6373e-02,  1.5361e-01,  4.8800e-02]],\n",
      "\n",
      "         [[-5.4704e-02, -3.1466e-02,  1.0790e-02],\n",
      "          [-5.3640e-02,  1.4642e-02, -5.6520e-02],\n",
      "          [ 3.9935e-02,  3.6350e-02,  1.0166e-02]],\n",
      "\n",
      "         [[ 3.8967e-02,  5.5248e-02,  3.8713e-02],\n",
      "          [ 5.4566e-02,  2.6337e-02,  5.3304e-02],\n",
      "          [ 5.1054e-02, -4.6979e-02, -2.0345e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5334e-02, -1.4826e-02,  5.6494e-02],\n",
      "          [ 1.3417e-01,  3.5091e-02,  2.7160e-02],\n",
      "          [-5.3563e-02, -5.6937e-02, -4.5920e-02]],\n",
      "\n",
      "         [[ 2.7144e-02, -3.4861e-02, -2.7368e-02],\n",
      "          [-3.7287e-02,  1.9552e-02,  1.1330e-03],\n",
      "          [-4.3759e-02, -2.7531e-03,  3.9221e-02]],\n",
      "\n",
      "         [[-1.1521e-01,  2.4924e-02,  3.5006e-02],\n",
      "          [-3.7925e-03, -3.9437e-02,  9.4766e-03],\n",
      "          [-3.4654e-02,  5.5907e-02, -9.1880e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.8463e-02,  2.0318e-02, -7.7849e-03],\n",
      "          [-3.2380e-02, -2.1730e-02, -1.6589e-01],\n",
      "          [-5.2511e-02,  4.6011e-02,  3.9154e-02]],\n",
      "\n",
      "         [[-3.9803e-02, -4.5345e-02,  2.7641e-03],\n",
      "          [ 3.8585e-02, -4.4772e-02, -2.2182e-02],\n",
      "          [-3.8162e-02,  4.4383e-02,  8.0627e-02]],\n",
      "\n",
      "         [[-2.7344e-02,  2.4100e-02,  3.6906e-02],\n",
      "          [ 5.5127e-02, -9.7398e-04,  3.4720e-02],\n",
      "          [ 7.4312e-03, -1.9777e-02,  5.4639e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0461e-03, -3.1087e-02,  4.7640e-02],\n",
      "          [ 2.8032e-02, -9.0363e-03,  5.0352e-02],\n",
      "          [-7.2327e-03,  3.5587e-02, -4.1312e-02]],\n",
      "\n",
      "         [[-4.6527e-02,  4.4287e-02,  4.9405e-02],\n",
      "          [ 3.0018e-02, -2.2550e-02, -1.7468e-02],\n",
      "          [-1.2349e-02,  4.1373e-02,  2.5493e-02]],\n",
      "\n",
      "         [[-2.2797e-03, -4.5481e-02,  3.1606e-02],\n",
      "          [ 3.4781e-02,  5.3672e-02,  5.0954e-03],\n",
      "          [-1.6525e-02, -4.5971e-02,  3.6182e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.2774e-02, -3.5624e-02, -3.3103e-02],\n",
      "          [ 5.7730e-02, -5.1856e-02, -3.0941e-02],\n",
      "          [-3.5199e-02, -7.5430e-02, -5.0761e-02]],\n",
      "\n",
      "         [[ 7.0573e-02, -7.2163e-02, -3.1994e-02],\n",
      "          [-5.5698e-02, -3.6539e-02,  3.3959e-02],\n",
      "          [-4.1320e-02, -4.8156e-02,  4.5794e-02]],\n",
      "\n",
      "         [[ 6.3476e-03, -5.2881e-02, -6.5879e-02],\n",
      "          [ 3.0966e-02, -4.5067e-02, -5.5679e-02],\n",
      "          [ 3.6263e-02, -3.3655e-02,  5.4953e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4053e-02,  5.8124e-02, -2.0959e-02],\n",
      "          [-4.3465e-02, -4.9091e-02, -1.8386e-02],\n",
      "          [ 5.7077e-02,  7.9230e-02,  1.5751e-02]],\n",
      "\n",
      "         [[ 4.6411e-02,  4.9007e-02, -2.5358e-02],\n",
      "          [ 1.5051e-02,  3.7063e-02,  5.4220e-02],\n",
      "          [ 3.7565e-02, -4.5259e-02, -6.7111e-03]],\n",
      "\n",
      "         [[-7.9783e-03,  8.7524e-02, -3.3240e-02],\n",
      "          [ 3.3677e-02, -3.4597e-02,  2.7495e-02],\n",
      "          [ 1.1515e-03,  3.9161e-02, -3.4712e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0654e-02, -4.5394e-02, -4.5710e-02],\n",
      "          [-5.7007e-02, -3.4371e-02,  2.7160e-02],\n",
      "          [ 4.0845e-02,  1.1524e-02, -2.2617e-02]],\n",
      "\n",
      "         [[-4.8987e-02, -3.9491e-02,  4.2120e-03],\n",
      "          [ 1.2155e-02, -6.3815e-03, -8.0551e-03],\n",
      "          [-4.4012e-02,  4.2209e-02, -5.7668e-03]],\n",
      "\n",
      "         [[ 2.7864e-02,  3.6634e-02,  6.4850e-02],\n",
      "          [ 3.6666e-02, -4.4580e-02,  3.1963e-03],\n",
      "          [-4.0330e-02,  3.0814e-02, -1.5639e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6234e-03,  4.8309e-02, -5.7121e-02],\n",
      "          [ 3.3867e-02, -6.8414e-02,  2.2409e-02],\n",
      "          [-2.9280e-02,  4.7182e-02,  1.2645e-02]],\n",
      "\n",
      "         [[-3.7198e-03, -5.3605e-02, -1.0893e-02],\n",
      "          [-3.4468e-03,  3.7757e-02,  3.2868e-02],\n",
      "          [ 3.3144e-02, -1.6749e-02,  3.1239e-03]],\n",
      "\n",
      "         [[ 5.4630e-02,  2.2319e-02, -5.6283e-02],\n",
      "          [ 5.4167e-02, -5.4708e-02,  3.0010e-02],\n",
      "          [-6.8019e-02, -4.0212e-02,  3.3548e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.0848e-02,  3.8509e-02,  8.7960e-03],\n",
      "          [ 4.8607e-03,  5.6212e-02,  5.4569e-02],\n",
      "          [-2.9694e-02,  3.3421e-02,  3.4259e-02]],\n",
      "\n",
      "         [[-2.7246e-03, -3.2238e-02, -4.6495e-02],\n",
      "          [ 3.9090e-02,  3.6645e-03, -3.2891e-02],\n",
      "          [-4.7285e-02,  4.2395e-02,  8.1490e-02]],\n",
      "\n",
      "         [[-2.7975e-02,  5.8570e-02,  3.4966e-03],\n",
      "          [-9.9682e-03,  4.6019e-02, -8.2130e-02],\n",
      "          [-2.8650e-02, -7.7571e-02, -9.2110e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.3673e-02, -4.8780e-02,  3.9996e-02],\n",
      "          [-5.6333e-02, -5.0880e-02,  8.3525e-02],\n",
      "          [-2.7585e-02, -1.0708e-01,  4.9130e-02]],\n",
      "\n",
      "         [[-2.9616e-03, -5.7815e-02, -4.9642e-02],\n",
      "          [ 1.6692e-02, -3.2470e-02, -5.1334e-02],\n",
      "          [-6.4858e-02, -2.1673e-02,  4.0417e-03]],\n",
      "\n",
      "         [[-5.2807e-02,  5.8724e-02, -5.5885e-03],\n",
      "          [-5.8468e-02, -2.6610e-02,  4.5639e-02],\n",
      "          [ 5.1057e-02,  5.1103e-02,  3.1140e-02]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[[[ 0., -1.,  1.],\n",
      "          [-1.,  1.,  0.],\n",
      "          [ 0.,  0.,  1.]],\n",
      "\n",
      "         [[ 1., -1.,  0.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.,  0.],\n",
      "          [ 0., -1., -1.],\n",
      "          [ 0.,  0., -1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0., -1.,  1.],\n",
      "          [ 0., -1.,  0.],\n",
      "          [-1.,  0.,  0.]],\n",
      "\n",
      "         [[-1., -1.,  0.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1.,  1.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 0., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  0.],\n",
      "          [-1.,  0., -1.],\n",
      "          [ 1.,  1.,  0.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [ 1., -1.,  0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  0.,  1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1.],\n",
      "          [-1.,  0.,  0.],\n",
      "          [-1.,  0.,  1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [ 0., -1.,  0.],\n",
      "          [-1.,  1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  0.,  0.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  0.],\n",
      "          [ 1., -1., -1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [ 1.,  0.,  1.],\n",
      "          [ 0.,  0.,  1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0., -1.,  1.],\n",
      "          [ 1.,  0.,  1.],\n",
      "          [ 0.,  1., -1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [ 1., -1.,  0.],\n",
      "          [ 0.,  1.,  1.]],\n",
      "\n",
      "         [[ 0., -1.,  1.],\n",
      "          [ 1.,  1.,  0.],\n",
      "          [ 0., -1.,  1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [-1., -1.,  1.]],\n",
      "\n",
      "         [[ 0., -1., -1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 1., -1.,  1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [-1., -1.,  0.],\n",
      "          [ 1.,  1.,  0.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [ 0.,  1.,  1.],\n",
      "          [ 1., -1.,  0.]],\n",
      "\n",
      "         [[ 0.,  1., -1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [ 0.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1.,  0., -1.]],\n",
      "\n",
      "         [[-1., -1.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [-1.,  1.,  0.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [ 1., -1.,  0.],\n",
      "          [-1.,  1.,  0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.,  1., -1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [-1.,  1.,  0.]],\n",
      "\n",
      "         [[ 0., -1.,  0.],\n",
      "          [ 0.,  1.,  1.],\n",
      "          [ 1.,  0.,  0.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [-1., -1.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[-1.,  1.,  0.],\n",
      "          [ 0.,  1.,  1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[ 0., -1., -1.],\n",
      "          [ 1.,  0., -1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[-1.,  1.,  0.],\n",
      "          [ 0.,  1., -1.],\n",
      "          [-1., -1.,  0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [-1., -1.,  1.]],\n",
      "\n",
      "         [[ 0., -1., -1.],\n",
      "          [ 0., -1., -1.],\n",
      "          [-1., -1.,  0.]],\n",
      "\n",
      "         [[-1.,  1.,  0.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1.,  1.,  1.]]]], device='cuda:0', grad_fn=<_ternary_pyBackward>)\n"
     ]
    }
   ],
   "source": [
    "a = model_b(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_b.named_parameters():\n",
    "    if(name == 'conv1.weight'):\n",
    "        x = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.],\n",
       "         [ 0., -1., -1.],\n",
       "         [ 1.,  0.,  1.]]], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ternary(x[0],0.1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.],\n",
       "        [ 0., -1., -1.],\n",
       "        [ 1.,  0.,  1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _ternary(x: torch.Tensor, delta: float):\n",
    "    return (x >= delta).float() - (x <= -delta).float()\n",
    "_ternary(tensor,0.1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ternary(input,0.2969)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.,  1., -1.,  1., -1.,  1.,  0.],\n",
      "          [-1.,  1., -1.,  1., -1.,  1.,  0.],\n",
      "          [-1.,  1., -1.,  1., -1.,  1.,  0.],\n",
      "          [-1.,  1., -1.,  1., -1.,  1.,  0.],\n",
      "          [-1.,  1., -1.,  1., -1.,  1.,  0.],\n",
      "          [-1.,  1., -1.,  1., -1.,  1.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "image = torch.tensor([[[[ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "                        [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "                        [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "                        [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "                        [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "                        [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "                        [ 1., -1.,  1., -1.,  1., -1.,  1.]]]], device='cuda:0')\n",
    "\n",
    "kernel = torch.tensor([[ 2.2384e-01,  2.2946e-01,  2.7293e-01],\n",
    "                        [-9.5651e-04, -2.6885e-01, -2.5753e-01],\n",
    "                        [ 1.5774e-01,  1.4375e-01,  6.2775e-01]], device='cuda:0')\n",
    "\n",
    "# Thêm chiều cho kernel để phù hợp với yêu cầu của hàm conv2d\n",
    "kernel = kernel.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Thực hiện tích chập\n",
    "output = F.conv2d(_ternary(image,0.2969), _ternary(kernel,0.5), padding=1)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 1.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ternary(kernel,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "          [-1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "          [-1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "          [-1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "          [-1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "          [-1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "          [ 0.,  1., -1.,  1., -1.,  1., -1.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ternary(output,0.1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 2.2384e-01,  2.2946e-01,  2.7293e-01],\n",
       "                        [-9.5651e-04, -2.6885e-01, -2.5753e-01],\n",
       "                        [ 1.5774e-01,  1.4375e-01,  6.2775e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.7201e-01, -3.0356e-01,  2.7134e-01],\n",
       "                        [-4.3390e-02,  1.4793e-01,  1.4906e-01],\n",
       "                        [ 4.0869e-01, -1.7056e-01, -2.2095e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4437e-01, -1.8334e-01, -2.1462e-01],\n",
       "                        [ 2.9422e-01,  4.7742e-01,  8.8640e-01],\n",
       "                        [-2.5724e-01,  2.4763e-01, -1.9743e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3729e-01, -3.0430e-01, -3.1893e-01],\n",
       "                        [-4.3160e-01,  2.2575e-01, -5.6895e-01],\n",
       "                        [-4.7998e-02, -2.6802e-01, -8.5414e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3040e-01, -2.5569e-01,  1.6291e-01],\n",
       "                        [ 1.0130e-01, -1.9798e-01, -2.3457e-01],\n",
       "                        [ 4.7315e-02,  2.8065e-01, -7.1974e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2168e-01,  2.4957e-01, -1.7423e-01],\n",
       "                        [-2.8821e-01,  8.3267e-02, -3.2709e-01],\n",
       "                        [ 2.8243e-01,  1.2911e-01, -2.6657e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5369e-01,  6.5130e-01,  4.1395e-01],\n",
       "                        [-3.0483e-01,  3.2942e-01, -3.0655e-01],\n",
       "                        [ 3.2622e-01, -4.0352e-01, -5.6392e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5243e-03,  2.4588e-01,  4.0350e-02],\n",
       "                        [-2.0812e-01,  2.4641e-01,  2.3137e-01],\n",
       "                        [ 1.2412e-01, -4.0625e-02,  8.6534e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8890e-01, -4.3219e-01, -1.0766e+00],\n",
       "                        [ 6.9136e-01, -3.4737e-01,  2.1509e-01],\n",
       "                        [-3.2395e-01,  2.4559e-01,  6.7190e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6704e-04, -1.5736e-01,  7.5594e-01],\n",
       "                        [-3.2410e-01, -2.7281e-01,  2.2335e-01],\n",
       "                        [-3.8025e-01, -2.6742e-01,  3.0619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0097e-01, -2.5631e-01,  2.6483e-01],\n",
       "                        [ 2.6394e-01, -2.5804e-01, -8.0675e-03],\n",
       "                        [ 2.9984e-01, -7.5616e-02, -4.0549e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0280e-01, -2.0193e-01,  2.7382e-01],\n",
       "                        [ 2.6613e-01, -2.5849e-01, -1.9345e+00],\n",
       "                        [ 3.2329e-01, -2.7633e-01, -4.8165e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5099e-01, -2.6880e-01,  2.7130e-01],\n",
       "                        [-2.8255e-01,  9.1935e-01, -5.9180e-03],\n",
       "                        [ 2.3400e-01,  1.4861e-01,  1.6592e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6231e-04,  2.7115e-01,  3.1996e-01],\n",
       "                        [-2.7939e-01, -2.7252e-01,  2.8857e-01],\n",
       "                        [ 2.1303e-01,  2.0316e-01, -4.4617e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5069e-01, -2.7645e-01, -2.5495e-01],\n",
       "                        [ 3.2738e-01,  2.1655e-01, -1.5736e-01],\n",
       "                        [ 6.7990e-02,  6.2676e-01,  6.6373e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6545e-01,  2.5991e-01,  2.9329e-01],\n",
       "                        [-5.9127e-01,  2.1050e-01, -2.7656e-01],\n",
       "                        [ 3.0206e-01,  1.1274e-01, -4.1250e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2719e-01, -7.2225e-01, -2.7552e-01],\n",
       "                        [ 5.7175e-03, -3.7580e-01,  1.5014e-01],\n",
       "                        [ 9.3449e-04, -2.3818e-01, -1.2727e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8943e-01,  2.8270e-01,  5.6072e-02],\n",
       "                        [-1.3629e-01, -3.1980e-01, -2.8103e-01],\n",
       "                        [ 2.3651e-01,  2.9135e-01, -1.7916e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3225e-02,  2.7018e-01,  4.4950e-01],\n",
       "                        [-6.9819e-01, -9.3881e-02,  3.3286e-01],\n",
       "                        [ 2.8709e-01, -1.9406e-01, -5.2635e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9002e-01, -3.0258e-03, -2.3074e-02],\n",
       "                        [-1.8975e-01, -1.7533e-01,  1.5104e-01],\n",
       "                        [ 2.2151e-01, -6.3582e-01, -2.9002e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4779e-01, -1.2406e-01, -2.3031e-01],\n",
       "                        [-2.8373e-01,  1.5371e-01, -3.0812e-01],\n",
       "                        [ 2.9658e-01, -9.9534e-02, -3.4029e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3085e-01, -2.3487e-01,  2.8189e-01],\n",
       "                        [-3.3903e-01, -1.8038e-01, -2.6319e-01],\n",
       "                        [ 2.2155e-01,  3.7524e-01, -2.6153e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1120e-01, -6.0533e-03, -1.6118e-01],\n",
       "                        [-2.7198e-01, -2.6335e-01,  9.2882e-01],\n",
       "                        [ 2.9719e-01,  1.5651e-01, -2.0623e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3265e-01, -8.9535e-02,  3.0907e-01],\n",
       "                        [ 1.8578e-01, -2.8643e-01,  2.6292e-01],\n",
       "                        [-2.5204e-02, -2.3164e-01, -2.1972e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2361e-01, -5.4247e-01, -2.7578e-01],\n",
       "                        [-2.5149e-01,  2.2032e-01,  2.0326e-01],\n",
       "                        [-3.2391e-01,  3.1960e-01,  3.5584e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2196e-02,  2.1249e-01,  2.5696e-01],\n",
       "                        [ 2.7084e-01,  2.4867e-01,  2.1187e-01],\n",
       "                        [-1.8707e-01,  6.2833e-01,  1.8989e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6757e-01, -5.1529e-01, -2.4353e-01],\n",
       "                        [ 2.6488e-01,  4.0302e-01,  2.7264e-01],\n",
       "                        [ 1.2835e-01,  3.1480e-01, -2.8174e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4413e-01, -5.5380e-01, -1.9826e-01],\n",
       "                        [ 2.6536e-01,  2.6967e-01, -1.3370e-01],\n",
       "                        [-3.1721e-01, -1.3163e-01,  3.1064e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6557e-02,  9.5948e-01,  2.0657e-01],\n",
       "                        [-1.8933e-01,  3.1061e-01,  3.4915e-01],\n",
       "                        [-3.1657e-01,  2.2791e-01, -2.9310e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6985e-01,  6.0079e-01, -2.5943e-01],\n",
       "                        [ 2.8702e-01, -5.4185e-01,  3.1700e-01],\n",
       "                        [-1.9499e-01,  3.1507e-02,  3.0105e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4794e-01,  2.2433e-01,  7.9008e-01],\n",
       "                        [ 1.1296e+00,  4.4845e-01,  1.1651e-01],\n",
       "                        [-2.3740e-01, -2.4891e-01, -3.3032e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3609e-01,  2.4975e-01,  2.3865e-01],\n",
       "                        [-2.9519e-01,  2.6365e-01, -1.3488e-01],\n",
       "                        [ 1.2022e-01, -1.4573e-01, -3.0155e-01]]]], device='cuda:0')),\n",
       "             ('conv1.input_quantizer.running_delta',\n",
       "              tensor([0.2969], device='cuda:0')),\n",
       "             ('conv1.weight_quantizer.running_delta',\n",
       "              tensor([0.1440], device='cuda:0')),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 1.2261e-03, -5.0895e-02,  4.7574e-02],\n",
       "                        [-5.6012e-02,  2.2410e-02, -1.9850e-03],\n",
       "                        [ 2.3949e-03, -4.8149e-03,  6.4186e-02]],\n",
       "              \n",
       "                       [[ 4.1882e-02, -5.6124e-02,  2.5328e-03],\n",
       "                        [-5.8204e-02, -3.6482e-02, -4.6972e-02],\n",
       "                        [-2.6420e-02, -4.3066e-02, -3.1011e-02]],\n",
       "              \n",
       "                       [[ 3.5761e-02,  4.0774e-02,  1.4294e-02],\n",
       "                        [ 1.7810e-02, -2.5733e-02, -4.3966e-02],\n",
       "                        [ 1.7685e-02, -1.2772e-02, -5.8158e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.9482e-03, -4.1478e-02,  2.3330e-02],\n",
       "                        [-1.8408e-02, -5.8509e-02,  1.3930e-02],\n",
       "                        [-3.3617e-02, -4.1382e-03,  2.0730e-03]],\n",
       "              \n",
       "                       [[-2.7635e-02, -4.0778e-02,  1.0692e-02],\n",
       "                        [-2.2010e-02, -5.7329e-02,  4.5885e-02],\n",
       "                        [ 3.8183e-02,  6.8794e-02,  1.0223e-02]],\n",
       "              \n",
       "                       [[-7.1052e-05, -9.3283e-03,  1.6465e-02],\n",
       "                        [-5.4625e-02,  3.2046e-02,  3.7009e-02],\n",
       "                        [-8.0056e-04, -2.7785e-02, -3.1864e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.6236e-02,  3.2165e-02,  3.0002e-02],\n",
       "                        [-5.0317e-02, -8.9126e-02, -4.2363e-02],\n",
       "                        [-3.6373e-02,  1.5361e-01,  4.8800e-02]],\n",
       "              \n",
       "                       [[-5.4704e-02, -3.1466e-02,  1.0790e-02],\n",
       "                        [-5.3640e-02,  1.4642e-02, -5.6520e-02],\n",
       "                        [ 3.9935e-02,  3.6350e-02,  1.0166e-02]],\n",
       "              \n",
       "                       [[ 3.8967e-02,  5.5248e-02,  3.8713e-02],\n",
       "                        [ 5.4566e-02,  2.6337e-02,  5.3304e-02],\n",
       "                        [ 5.1054e-02, -4.6979e-02, -2.0345e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5334e-02, -1.4826e-02,  5.6494e-02],\n",
       "                        [ 1.3417e-01,  3.5091e-02,  2.7160e-02],\n",
       "                        [-5.3563e-02, -5.6937e-02, -4.5920e-02]],\n",
       "              \n",
       "                       [[ 2.7144e-02, -3.4861e-02, -2.7368e-02],\n",
       "                        [-3.7287e-02,  1.9552e-02,  1.1330e-03],\n",
       "                        [-4.3759e-02, -2.7531e-03,  3.9221e-02]],\n",
       "              \n",
       "                       [[-1.1521e-01,  2.4924e-02,  3.5006e-02],\n",
       "                        [-3.7925e-03, -3.9437e-02,  9.4766e-03],\n",
       "                        [-3.4654e-02,  5.5907e-02, -9.1880e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8463e-02,  2.0318e-02, -7.7849e-03],\n",
       "                        [-3.2380e-02, -2.1730e-02, -1.6589e-01],\n",
       "                        [-5.2511e-02,  4.6011e-02,  3.9154e-02]],\n",
       "              \n",
       "                       [[-3.9803e-02, -4.5345e-02,  2.7641e-03],\n",
       "                        [ 3.8585e-02, -4.4772e-02, -2.2182e-02],\n",
       "                        [-3.8162e-02,  4.4383e-02,  8.0627e-02]],\n",
       "              \n",
       "                       [[-2.7344e-02,  2.4100e-02,  3.6906e-02],\n",
       "                        [ 5.5127e-02, -9.7398e-04,  3.4720e-02],\n",
       "                        [ 7.4312e-03, -1.9777e-02,  5.4639e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0461e-03, -3.1087e-02,  4.7640e-02],\n",
       "                        [ 2.8032e-02, -9.0363e-03,  5.0352e-02],\n",
       "                        [-7.2327e-03,  3.5587e-02, -4.1312e-02]],\n",
       "              \n",
       "                       [[-4.6527e-02,  4.4287e-02,  4.9405e-02],\n",
       "                        [ 3.0018e-02, -2.2550e-02, -1.7468e-02],\n",
       "                        [-1.2349e-02,  4.1373e-02,  2.5493e-02]],\n",
       "              \n",
       "                       [[-2.2797e-03, -4.5481e-02,  3.1606e-02],\n",
       "                        [ 3.4781e-02,  5.3672e-02,  5.0954e-03],\n",
       "                        [-1.6525e-02, -4.5971e-02,  3.6182e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-4.2774e-02, -3.5624e-02, -3.3103e-02],\n",
       "                        [ 5.7730e-02, -5.1856e-02, -3.0941e-02],\n",
       "                        [-3.5199e-02, -7.5430e-02, -5.0761e-02]],\n",
       "              \n",
       "                       [[ 7.0573e-02, -7.2163e-02, -3.1994e-02],\n",
       "                        [-5.5698e-02, -3.6539e-02,  3.3959e-02],\n",
       "                        [-4.1320e-02, -4.8156e-02,  4.5794e-02]],\n",
       "              \n",
       "                       [[ 6.3476e-03, -5.2881e-02, -6.5879e-02],\n",
       "                        [ 3.0966e-02, -4.5067e-02, -5.5679e-02],\n",
       "                        [ 3.6263e-02, -3.3655e-02,  5.4953e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4053e-02,  5.8124e-02, -2.0959e-02],\n",
       "                        [-4.3465e-02, -4.9091e-02, -1.8386e-02],\n",
       "                        [ 5.7077e-02,  7.9230e-02,  1.5751e-02]],\n",
       "              \n",
       "                       [[ 4.6411e-02,  4.9007e-02, -2.5358e-02],\n",
       "                        [ 1.5051e-02,  3.7063e-02,  5.4220e-02],\n",
       "                        [ 3.7565e-02, -4.5259e-02, -6.7111e-03]],\n",
       "              \n",
       "                       [[-7.9783e-03,  8.7524e-02, -3.3240e-02],\n",
       "                        [ 3.3677e-02, -3.4597e-02,  2.7495e-02],\n",
       "                        [ 1.1515e-03,  3.9161e-02, -3.4712e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0654e-02, -4.5394e-02, -4.5710e-02],\n",
       "                        [-5.7007e-02, -3.4371e-02,  2.7160e-02],\n",
       "                        [ 4.0845e-02,  1.1524e-02, -2.2617e-02]],\n",
       "              \n",
       "                       [[-4.8987e-02, -3.9491e-02,  4.2120e-03],\n",
       "                        [ 1.2155e-02, -6.3815e-03, -8.0551e-03],\n",
       "                        [-4.4012e-02,  4.2209e-02, -5.7668e-03]],\n",
       "              \n",
       "                       [[ 2.7864e-02,  3.6634e-02,  6.4850e-02],\n",
       "                        [ 3.6666e-02, -4.4580e-02,  3.1963e-03],\n",
       "                        [-4.0330e-02,  3.0814e-02, -1.5639e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.6234e-03,  4.8309e-02, -5.7121e-02],\n",
       "                        [ 3.3867e-02, -6.8414e-02,  2.2409e-02],\n",
       "                        [-2.9280e-02,  4.7182e-02,  1.2645e-02]],\n",
       "              \n",
       "                       [[-3.7198e-03, -5.3605e-02, -1.0893e-02],\n",
       "                        [-3.4468e-03,  3.7757e-02,  3.2868e-02],\n",
       "                        [ 3.3144e-02, -1.6749e-02,  3.1239e-03]],\n",
       "              \n",
       "                       [[ 5.4630e-02,  2.2319e-02, -5.6283e-02],\n",
       "                        [ 5.4167e-02, -5.4708e-02,  3.0010e-02],\n",
       "                        [-6.8019e-02, -4.0212e-02,  3.3548e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0848e-02,  3.8509e-02,  8.7960e-03],\n",
       "                        [ 4.8607e-03,  5.6212e-02,  5.4569e-02],\n",
       "                        [-2.9694e-02,  3.3421e-02,  3.4259e-02]],\n",
       "              \n",
       "                       [[-2.7246e-03, -3.2238e-02, -4.6495e-02],\n",
       "                        [ 3.9090e-02,  3.6645e-03, -3.2891e-02],\n",
       "                        [-4.7285e-02,  4.2395e-02,  8.1490e-02]],\n",
       "              \n",
       "                       [[-2.7975e-02,  5.8570e-02,  3.4966e-03],\n",
       "                        [-9.9682e-03,  4.6019e-02, -8.2130e-02],\n",
       "                        [-2.8650e-02, -7.7571e-02, -9.2110e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.3673e-02, -4.8780e-02,  3.9996e-02],\n",
       "                        [-5.6333e-02, -5.0880e-02,  8.3525e-02],\n",
       "                        [-2.7585e-02, -1.0708e-01,  4.9130e-02]],\n",
       "              \n",
       "                       [[-2.9616e-03, -5.7815e-02, -4.9642e-02],\n",
       "                        [ 1.6692e-02, -3.2470e-02, -5.1334e-02],\n",
       "                        [-6.4858e-02, -2.1673e-02,  4.0417e-03]],\n",
       "              \n",
       "                       [[-5.2807e-02,  5.8724e-02, -5.5885e-03],\n",
       "                        [-5.8468e-02, -2.6610e-02,  4.5639e-02],\n",
       "                        [ 5.1057e-02,  5.1103e-02,  3.1140e-02]]]], device='cuda:0')),\n",
       "             ('conv2.input_quantizer.running_delta',\n",
       "              tensor([0.7582], device='cuda:0')),\n",
       "             ('conv2.weight_quantizer.running_delta',\n",
       "              tensor([0.0220], device='cuda:0')),\n",
       "             ('linear1.weight',\n",
       "              tensor([[ 4.0897e-03,  2.9592e-03,  4.4773e-03,  ..., -1.1723e-03,\n",
       "                        1.2998e-02, -1.5000e-02],\n",
       "                      [-3.0638e-05, -1.3145e-02, -9.1354e-03,  ...,  1.5934e-02,\n",
       "                        7.3834e-03,  1.6458e-02],\n",
       "                      [ 1.6105e-02, -1.5279e-02,  1.2721e-02,  ..., -7.3802e-03,\n",
       "                        9.6832e-03,  1.2943e-02],\n",
       "                      ...,\n",
       "                      [-5.0598e-03,  1.0004e-02, -1.7640e-02,  ..., -7.2392e-03,\n",
       "                       -1.5996e-03, -2.0007e-03],\n",
       "                      [-4.3095e-03, -1.0581e-02, -1.2277e-02,  ..., -1.5034e-02,\n",
       "                       -4.4115e-03,  8.9476e-03],\n",
       "                      [-1.6724e-02,  1.9319e-03,  1.4144e-03,  ..., -1.0024e-03,\n",
       "                       -6.0113e-03,  4.5605e-03]], device='cuda:0')),\n",
       "             ('linear1.input_quantizer.running_delta',\n",
       "              tensor([6.5196], device='cuda:0')),\n",
       "             ('linear1.weight_quantizer.running_delta',\n",
       "              tensor([0.0060], device='cuda:0')),\n",
       "             ('linear2.weight',\n",
       "              tensor([[-0.0072, -0.0756,  0.0473,  0.0289,  0.0643, -0.0315, -0.0756, -0.0411,\n",
       "                       -0.0284, -0.0712,  0.0448,  0.0759,  0.0543, -0.0124,  0.0690,  0.0008,\n",
       "                       -0.0849, -0.0029, -0.0573,  0.0785,  0.0451, -0.0109, -0.0683,  0.0367,\n",
       "                       -0.0608,  0.0044,  0.0177, -0.0293, -0.0184,  0.0792,  0.0038,  0.0405,\n",
       "                        0.0617, -0.0633,  0.0338, -0.0578, -0.0588,  0.0600,  0.0492,  0.0447,\n",
       "                        0.0137,  0.0175,  0.0672, -0.0420,  0.0241,  0.0165, -0.0862, -0.0100,\n",
       "                        0.0193,  0.0158,  0.0108,  0.0797,  0.0609,  0.0109, -0.0017,  0.0541,\n",
       "                       -0.0008, -0.0631, -0.0687,  0.0217,  0.0379,  0.0848, -0.0409,  0.0580,\n",
       "                        0.0504, -0.0639, -0.0432,  0.0212, -0.0457,  0.0138,  0.0429, -0.0350,\n",
       "                        0.0389, -0.0750,  0.0321,  0.0588, -0.0592, -0.0264,  0.0253, -0.0798,\n",
       "                       -0.0560, -0.0593,  0.0351, -0.0553, -0.0853, -0.0485,  0.0564, -0.0274,\n",
       "                       -0.0004, -0.0043,  0.0061, -0.0182,  0.0614, -0.0265, -0.0772,  0.0672,\n",
       "                        0.0129, -0.0546,  0.0550, -0.0387, -0.0781,  0.0719,  0.0208,  0.0046,\n",
       "                       -0.0848, -0.0468,  0.0083, -0.0317, -0.0387,  0.0364,  0.0244,  0.0573,\n",
       "                       -0.0025, -0.0021, -0.0134, -0.0339, -0.0723,  0.0659, -0.0868, -0.0058,\n",
       "                       -0.0479,  0.0474,  0.0571,  0.0145,  0.0857, -0.0285,  0.0749, -0.0642],\n",
       "                      [-0.0206,  0.0831, -0.0437, -0.0433, -0.0808, -0.0513,  0.0008,  0.0155,\n",
       "                       -0.0281, -0.0644,  0.0620, -0.0505,  0.0814,  0.0744, -0.0121, -0.0082,\n",
       "                       -0.0876,  0.0488, -0.0713, -0.0295, -0.0162,  0.0339,  0.0188, -0.0021,\n",
       "                       -0.0211, -0.0857,  0.0214,  0.0149, -0.0851,  0.0070, -0.0269,  0.0063,\n",
       "                        0.0408, -0.0640, -0.0540,  0.0073, -0.0010,  0.0249,  0.0769,  0.0631,\n",
       "                        0.0504,  0.0127,  0.0572,  0.0404, -0.0494, -0.0073,  0.0252,  0.0428,\n",
       "                        0.0411,  0.0096,  0.0257,  0.0503, -0.0520, -0.0734, -0.0545, -0.0366,\n",
       "                       -0.0669,  0.0569,  0.0053, -0.0507,  0.0133, -0.0602, -0.0029,  0.0835,\n",
       "                        0.0863,  0.0114, -0.0089, -0.0851, -0.0437,  0.0596,  0.0118,  0.0729,\n",
       "                       -0.0819, -0.0441, -0.0613, -0.0419,  0.0745, -0.0854,  0.0503,  0.0119,\n",
       "                       -0.0821, -0.0168,  0.0334,  0.0180, -0.0596, -0.0784,  0.0428, -0.0756,\n",
       "                        0.0319,  0.0421, -0.0232,  0.0422, -0.0127,  0.0371, -0.0075,  0.0033,\n",
       "                       -0.0340,  0.0470,  0.0507,  0.0490,  0.0253,  0.0374, -0.0465,  0.0038,\n",
       "                       -0.0479,  0.0270, -0.0756,  0.0861,  0.0128,  0.0318,  0.0016,  0.0565,\n",
       "                        0.0804, -0.0139, -0.0523,  0.0597,  0.0266, -0.0403,  0.0709, -0.0466,\n",
       "                       -0.0232,  0.0430,  0.0529, -0.0173,  0.0669,  0.0482, -0.0038, -0.0852],\n",
       "                      [ 0.0196,  0.0046,  0.0011,  0.0028,  0.0559,  0.0457, -0.0223, -0.0175,\n",
       "                        0.0264, -0.0806,  0.0759, -0.0639,  0.0373,  0.0672, -0.0461, -0.0515,\n",
       "                       -0.0116, -0.0566, -0.0867, -0.0857,  0.0175,  0.0089,  0.0531,  0.0424,\n",
       "                       -0.0785, -0.0693,  0.0410, -0.0661, -0.0519, -0.0669,  0.0416,  0.0041,\n",
       "                       -0.0675, -0.0015,  0.0094,  0.0169, -0.0850,  0.0836, -0.0133, -0.0668,\n",
       "                       -0.0687,  0.0653, -0.0332, -0.0730,  0.0707, -0.0020, -0.0484,  0.0719,\n",
       "                        0.0743, -0.0293, -0.0138, -0.0687, -0.0375, -0.0039, -0.0434,  0.0305,\n",
       "                        0.0844,  0.0344,  0.0553,  0.0637, -0.0802, -0.0264, -0.0576,  0.0518,\n",
       "                        0.0281,  0.0871,  0.0112, -0.0473,  0.0174,  0.0686, -0.0636, -0.0378,\n",
       "                       -0.0517, -0.0063,  0.0317, -0.0806,  0.0413,  0.0121,  0.0297,  0.0611,\n",
       "                        0.0170, -0.0232,  0.0440, -0.0165,  0.0538,  0.0731, -0.0517,  0.0483,\n",
       "                        0.0569, -0.0263, -0.0135,  0.0303,  0.0077,  0.0544,  0.0592, -0.0490,\n",
       "                       -0.0014,  0.0440,  0.0150,  0.0652,  0.0371,  0.0810,  0.0214, -0.0600,\n",
       "                       -0.0160,  0.0224,  0.0410, -0.0755,  0.0404, -0.0208,  0.0624, -0.0499,\n",
       "                        0.0610, -0.0401, -0.0801, -0.0645, -0.0097, -0.0038, -0.0243,  0.0587,\n",
       "                       -0.0509, -0.0067, -0.0507,  0.0369,  0.0267,  0.0649,  0.0786, -0.0316]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear2.input_quantizer.running_delta',\n",
       "              tensor([22.3651], device='cuda:0')),\n",
       "             ('linear2.weight_quantizer.running_delta',\n",
       "              tensor([0.0229], device='cuda:0'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1., -1.,  1., -1.,  1., -1.],\n",
       "        [ 0.,  2., -2.,  2., -2.,  2., -1.],\n",
       "        [ 0.,  2., -2.,  2., -2.,  2., -1.],\n",
       "        [ 0.,  2., -2.,  2., -2.,  2., -1.],\n",
       "        [ 0.,  2., -2.,  2., -2.,  2., -1.],\n",
       "        [ 0.,  2., -2.,  2., -2.,  2., -1.],\n",
       "        [ 0.,  1., -1.,  1., -1.,  1., -1.]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1., -1.,  ..., -1.,  1., -1.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          ...,\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -1.],\n",
      "          [ 0.,  1., -1.,  ..., -1.,  1., -1.]],\n",
      "\n",
      "         [[ 0.,  1., -1.,  ..., -1.,  1., -1.],\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          ...,\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          [-2.,  4., -4.,  ..., -4.,  4., -3.],\n",
      "          [-2.,  3., -3.,  ..., -3.,  3., -1.]],\n",
      "\n",
      "         [[ 1., -1.,  1.,  ...,  1., -1.,  2.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          ...,\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 0.,  2., -2.,  ..., -2.,  2., -2.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.,  3., -3.,  ..., -3.,  3., -1.],\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          ...,\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [-1.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
      "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 1., -1.,  1.,  ...,  1., -1.,  0.],\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          ...,\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          [ 1., -2.,  2.,  ...,  2., -2.,  2.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  2.]],\n",
      "\n",
      "         [[ 1., -2.,  2.,  ...,  2., -2.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          ...,\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "          [ 1., -1.,  1.,  ...,  1., -1.,  2.]]]], device='cuda:0',\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = model_b(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.],\n",
       "          [ 1., -1.,  1., -1.,  1., -1.,  1.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(1,1,7,7).to(device)\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        input[0][0][i][j] = np.power(-1,j)\n",
    "input.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_concatenate(arr):\n",
    "    # Chuyển đổi -1 thành 1 và 1 thành 0\n",
    "    arr = torch.flip(arr, dims=[0])\n",
    "    converted_arr = [1 if x == -1 else 0 for x in arr]\n",
    "    # Ghép các phần tử lại thành một chuỗi\n",
    "    concatenated_str = ''.join(map(str, converted_arr))\n",
    "\n",
    "    current_length = len(concatenated_str)\n",
    "    total_length = (np.ceil(current_length/32)*32).astype(int)\n",
    "    if current_length < total_length:\n",
    "        padding_length = int(total_length - current_length)\n",
    "        concatenated_str = '0' * padding_length + concatenated_str\n",
    "    # Chuyển chuỗi thành số nhị phân và sau đó thành số hex\n",
    "    hex_value = hex(int(concatenated_str, 2))[2:]  # Bỏ tiền tố '0x'\n",
    "\n",
    "    # Đảm bảo chuỗi hex đủ độ dài cần thiết\n",
    "    hex_length = total_length // 4  # 1 hex digit = 4 bits\n",
    "    if len(hex_value) < hex_length:\n",
    "        hex_value = '0' * (hex_length - len(hex_value)) + hex_value\n",
    "    return hex_value\n",
    "\n",
    "def to_hex(x):\n",
    "    return f\"0x{x:08x}\"\n",
    "\n",
    "def save_model_parameters_to_txt(model, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            layer_name = name.split('.')[0]\n",
    "            if 'conv' in name:\n",
    "                f.write(f'{name}\\n')\n",
    "                f.write(f'layer_name: {layer_name}\\n')\n",
    "                f.write(f'input_channel: {param.shape[1]}\\n')\n",
    "                f.write(f'output_channel: {param.shape[0]}\\n')\n",
    "                f.write(f'kernel_size: 3\\n')\n",
    "                f.write(f'stride: 1\\n')\n",
    "                f.write(f'padding: 1\\n')\n",
    "                f.write(f'dilation: 1\\n')\n",
    "                f.write(f'quant_type: 0\\n')\n",
    "                f.write(f'input_thres: 0\\n')\n",
    "                for param_e in param:\n",
    "                    sichannel = int(np.ceil(param_e.shape[0]/32))\n",
    "                    # param_q = torch.zeros([sichannel,param_e.shape[1],param_e.shape[2]])\n",
    "                    # param_q = param_q.int()\n",
    "                    for c in range(sichannel):\n",
    "                        for i in range(param_e.shape[1]):\n",
    "                            for j in range(param_e.shape[2]):\n",
    "                                hex_conv = convert_and_concatenate(_binary(param_e[sichannel*0:sichannel*32, i, j]))\n",
    "                                if j == param_e.shape[2]-1:\n",
    "                                    f.write(f'0x{hex_conv}')\n",
    "                                else:\n",
    "                                    f.write(f'0x{hex_conv}, ')\n",
    "                            f.write(f'\\n')\n",
    "                        f.write(f'\\n')\n",
    "            if 'fc' in name or 'linear' in name:\n",
    "                f.write(f'{name}\\n')\n",
    "                f.write(f'layer_name: {layer_name}\\n')\n",
    "                f.write(f'input_channel: {param.shape[1]}\\n')\n",
    "                f.write(f'output_channel: {param.shape[0]}\\n')\n",
    "                f.write(f'quant_type: 0\\n')\n",
    "                f.write(f'input_thres: 0.0\\n')\n",
    "                param = _binary(param)\n",
    "                for param_e in param:\n",
    "                    hex_conv = convert_and_concatenate(param_e)\n",
    "                    segments = [hex_conv[i:i+8] for i in range(0, len(hex_conv), 8)]\n",
    "                    segments.reverse()\n",
    "                    for segment in segments:\n",
    "                        f.write(f'0x{segment}\\n')\n",
    "                f.write(f'\\n')\n",
    "        return 0\n",
    "\n",
    "# Gọi hàm để lưu thông số mô hình\n",
    "a = save_model_parameters_to_txt(model_b, 'bcnn_model_parameters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([64, 32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model_b.named_parameters():\n",
    "    if 'conv' in name:\n",
    "        for param_e in param:\n",
    "            sichannel = int(np.ceil(param_e.shape[0]/32))\n",
    "            param_q = torch.zeros([sichannel,param_e.shape[1],param_e.shape[2]])\n",
    "            for c in range(sichannel):\n",
    "                for i in range(param_e.shape[1]):\n",
    "                    for j in range(param_e.shape[2]):\n",
    "                        param_q[c,i,j] = int(convert_and_concatenate(_binary(param_e[sichannel*0:sichannel*32, i, j])),16)\n",
    "            param_q = param_q.int()\n",
    "            # for i in param_q:\n",
    "            #     print(i)\n",
    "            # print(hex(param_q))\n",
    "            # print(f\"Giá trị hex: {hex(param_q)}\")\n",
    "            # print(hex(param_q))\n",
    "        print(param.shape)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryActivationFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Binarize input to -1 or 1\n",
    "        output = input.sign()\n",
    "        output[output==0] = 1\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input.abs() > 1] = 0\n",
    "        return grad_input\n",
    "\n",
    "class BinaryActivation(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return BinaryActivationFunction.apply(input)\n",
    "\n",
    "class QLinear(torch.nn.Linear):\n",
    "    qa_config = {}\n",
    "    qw_config = {}\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        # self.input_quantizer = BinaryActivation()\n",
    "        self.weight_quantizer = BinaryActivation()\n",
    "\n",
    "    def forward(self, input_f):\n",
    "        # input_t = self.input_quantizer(input_f)\n",
    "        weight_b = self.weight_quantizer(self.weight)\n",
    "        out = F.linear(input_f, weight_b, self.bias)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Validation Accuracy: 91.39%6\n",
      "Epoch [2/5], Validation Accuracy: 89.58%6\n",
      "Epoch [3/5], Validation Accuracy: 92.36%8\n",
      "Epoch [4/5], Validation Accuracy: 92.36%5\n",
      "Epoch [5/5], Validation Accuracy: 92.36%4\n",
      "Test Accuracy: 92.25%\n"
     ]
    }
   ],
   "source": [
    "class Netb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netb, self).__init__()\n",
    "        self.input_quantizer = BinaryActivation()\n",
    "\n",
    "        self.linear1 = QLinear(13, 128, bias = False)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.i1 = nn.Identity()\n",
    "\n",
    "        self.linear2 = QLinear(128, 128, bias = False)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.i2 = nn.Identity()\n",
    "\n",
    "        self.linear3 = QLinear(128, 128, bias = False)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        # self.i3 = nn.Identity()\n",
    "\n",
    "        self.linear4 = QLinear(128, 3, bias = False)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear2(x)\n",
    "        # x = self.bn2(x)\n",
    "        # x = self.i2(x)\n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear3(x)\n",
    "        # x = self.bn3(x)\n",
    "        # x = self.i3(x)\n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_b = Netb().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_b.parameters(), 0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model_b.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_b(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # model_ter1.set_weights_and_biases()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}', end='\\r')\n",
    "    \n",
    "    model_b.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_b(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Final evaluation on the test set\n",
    "model_b.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_b(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "torch.save(model_b.state_dict(), 'saved_best_model_bnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,\n",
       "          1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
       "         -1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "         -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "         -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "         -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "          1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "          1., -1.],\n",
       "        [-1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "         -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "         -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "         -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "          1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "          1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "         -1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "         -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1.,  1.],\n",
       "        [-1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,\n",
       "          1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "          1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,\n",
       "         -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,\n",
       "         -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "          1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,\n",
       "          1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "          1.,  1.]], device='cuda:0')"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BinaryActivationFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Binarize input to -1 or 1\n",
    "        output = input.sign()\n",
    "        output[output==0] = 1\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input.abs() > 1] = 0\n",
    "        return grad_input\n",
    "\n",
    "class BinaryActivation(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return BinaryActivationFunction.apply(input)\n",
    "\n",
    "class QLinear(torch.nn.Linear):\n",
    "    qa_config = {}\n",
    "    qw_config = {}\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.weight_quantizer = BinaryActivation()\n",
    "    def forward(self, input_f):\n",
    "        # weight_b = self.weight_quantizer(self.weight)\n",
    "        out = F.linear(input_f, self.weight, self.bias)\n",
    "        return out\n",
    "\n",
    "class Netb(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netb, self).__init__()\n",
    "        self.input_quantizer = BinaryActivation()\n",
    "        self.linear1 = QLinear(13, 128, bias = False)\n",
    "\n",
    "        self.linear2 = QLinear(128, 128, bias = False)\n",
    "\n",
    "        self.linear3 = QLinear(128, 128, bias = False)\n",
    "\n",
    "        self.linear4 = QLinear(128, 3, bias = False)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear1(x)\n",
    "        print(\"linear1\")\n",
    "        print(x)\n",
    "\n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear2(x)\n",
    "        print(\"linear2\")\n",
    "        print(x)\n",
    "\n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear3(x)\n",
    "        print(\"linear3\")\n",
    "        print(x)\n",
    "        \n",
    "        x = self.input_quantizer(x)\n",
    "        x = self.linear4(x)\n",
    "        print(\"linear4\")\n",
    "        print(x)\n",
    "        x = self.act4(x)\n",
    "        print(x)\n",
    "        return x\n",
    "\n",
    "model_bnn = Netb().to(device)\n",
    "model_bnn.linear1.state_dict()['weight'].copy_(model_b.linear1.state_dict()['weight'].sign())\n",
    "model_bnn.linear2.state_dict()['weight'].copy_(model_b.linear2.state_dict()['weight'].sign())\n",
    "model_bnn.linear3.state_dict()['weight'].copy_(model_b.linear3.state_dict()['weight'].sign())\n",
    "model_bnn.linear4.state_dict()['weight'].copy_(model_b.linear4.state_dict()['weight'].sign())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1\n",
      "tensor([[  5.,   7.,   7.,   1.,  -3.,  -3.,  -7.,   3.,  -1.,  -7.,  -3.,   3.,\n",
      "          -5.,   1.,   1.,   5.,  -5.,   1.,  -7.,   5.,   1.,   1.,  -1.,   1.,\n",
      "          -3.,   5.,  -3.,   3.,   1.,   5.,  -3.,   3.,   1.,  -3.,   5.,  -3.,\n",
      "          -3.,  -1.,   9.,  -1.,  -5.,   3.,   1.,   3.,   9.,   3.,   5.,  -7.,\n",
      "          -1.,   5.,   5.,  -3.,   3.,   5.,  -3.,   7.,  -3.,   5.,   3.,  -7.,\n",
      "           5.,  -1.,  -5.,  -3.,  -3.,   3.,  -7.,  -3.,  -3.,  -3.,   1.,   5.,\n",
      "           3.,   1.,  -1.,   1.,  -3.,  -1.,   3.,   1.,   1.,   3.,   1.,  -1.,\n",
      "           7.,  -3.,  -5.,  -5.,  -7.,  -3.,  -5.,  -1.,  -3.,  -5.,   1.,  -9.,\n",
      "          -3.,  -5.,   5.,  -3., -11.,   7.,  -1.,   3.,  -5.,   3.,  -3.,  -1.,\n",
      "           5.,  -5.,  -3.,  -7.,  -1.,  -5.,   5.,   1.,  -1.,   3.,  -7.,   5.,\n",
      "           3.,  -5.,  -5.,   5.,   7.,  -5.,  -3.,  -5.]], device='cuda:0')\n",
      "linear2\n",
      "tensor([[-24., -16., -14., -32., -32.,  20.,  -4., -16., -10.,  -8.,  10., -26.,\n",
      "         -22., -18., -20., -16.,  22.,  24.,  18., -12.,  24.,  12., -16., -24.,\n",
      "         -12., -20.,  30., -14.,   4.,  30.,  26., -28., -20., -18.,   6.,  24.,\n",
      "         -20.,  -6.,  -2.,   8., -22., -18.,  14.,  22., -10.,  -8., -22., -38.,\n",
      "         -12.,  -4.,  16., -18.,   8., -28.,  28., -22.,  44., -14.,  -8.,  10.,\n",
      "          14., -26.,  30.,  20.,   0.,  42.,   2., -22.,  12., -18.,  10.,  -8.,\n",
      "         -22.,  20., -22., -40.,  -8., -14.,  -8.,  18.,  16.,   4., -18., -14.,\n",
      "          22.,   6.,  14.,  22.,  24.,  14.,  12., -14., -20.,  -8., -34., -32.,\n",
      "           4.,  22.,   4.,  20.,  18., -10.,  -6.,   4.,  22., -14.,  12., -20.,\n",
      "         -12., -12.,  22.,   4.,  -6.,   8., -30.,  20.,  -4., -18., -18.,  14.,\n",
      "           0.,  26.,  20., -16., -22., -22., -18., -20.]], device='cuda:0')\n",
      "linear3\n",
      "tensor([[-22.,  -8.,  12.,  -6., -12.,  -6.,  -6.,   4.,  -2., -18., -10.,   2.,\n",
      "         -10.,  18., -18.,   8.,  22., -16.,  -4., -16.,   6.,  16.,  -2.,   8.,\n",
      "          -6.,  -2.,   2.,   2., -18., -24.,  -2.,   0.,  16., -30.,   2., -10.,\n",
      "         -12., -14., -36.,  -8.,  -4., -10.,   0.,  20.,  20.,  -6.,  18., -10.,\n",
      "           2.,   6., -16.,   4.,  -8., -16., -22.,   2.,  -4.,  -6.,   6.,  -2.,\n",
      "         -16.,  24.,  -2.,  -2.,   8., -20., -16.,  -4.,   0.,   0.,  16.,  -4.,\n",
      "         -22., -24.,  10.,  14., -10., -16., -14.,  26., -10.,  24.,  14.,  -6.,\n",
      "          12., -12., -14.,  16.,  -8.,  -2., -10.,  -4.,  20., -12.,   4.,  -8.,\n",
      "           6., -10., -10.,  18., -22.,  22.,  -8., -12.,   2., -12.,   4.,  -8.,\n",
      "           4.,  12.,   0., -18.,   8.,   8.,   4.,  24.,  10., -16., -18.,  -6.,\n",
      "         -10., -12.,   0.,  -4., -12.,  22.,   2.,  10.]], device='cuda:0')\n",
      "linear4\n",
      "tensor([[-24.,  10.,  26.]], device='cuda:0')\n",
      "tensor([[1.9287e-22, 1.1254e-07, 1.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_bnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "# images = torch.tensor([[0.0000,  0.0000,  0.0000,  0.0000, -0.6556,  0.9844,  0.2236, -1.4968, -1.4968, -0.9711, -0.1279,  0.2186,  0.2208]]).to(device)\n",
    "images = torch.tensor([[ 0.,          0.,          0.,          0.,         -0.48889792, -1.0158767,\n",
    "  0.2236068,  -1.4960896,  -1.4960909,   0.74484456, -0.1279424,   0.21856718,\n",
    "  0.22078077]]).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model_bnn(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.25%\n"
     ]
    }
   ],
   "source": [
    "model_bnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_bnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "# torch.save(model_bnn.state_dict(), 'saved_best_model_bnn_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_concatenate(arr):\n",
    "    # Chuyển đổi -1 thành 1 và 1 thành 0\n",
    "    arr = torch.flip(arr, dims=[0])\n",
    "    converted_arr = [1 if x == -1 else 0 for x in arr]\n",
    "    # Ghép các phần tử lại thành một chuỗi\n",
    "    concatenated_str = ''.join(map(str, converted_arr))\n",
    "\n",
    "    current_length = len(concatenated_str)\n",
    "    total_length = (np.ceil(current_length/32)*32).astype(int)\n",
    "    if current_length < total_length:\n",
    "        padding_length = int(total_length - current_length)\n",
    "        concatenated_str = '0' * padding_length + concatenated_str\n",
    "    # Chuyển chuỗi thành số nhị phân và sau đó thành số hex\n",
    "    hex_value = hex(int(concatenated_str, 2))[2:]  # Bỏ tiền tố '0x'\n",
    "\n",
    "    # Đảm bảo chuỗi hex đủ độ dài cần thiết\n",
    "    hex_length = total_length // 4  # 1 hex digit = 4 bits\n",
    "    if len(hex_value) < hex_length:\n",
    "        hex_value = '0' * (hex_length - len(hex_value)) + hex_value\n",
    "    return hex_value\n",
    "\n",
    "def save_model_parameters_to_txt(model, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.write(f'{name}\\n')\n",
    "            f.write(f'input_channel: {param.shape[1]}\\n')\n",
    "            f.write(f'output_channel: {param.shape[0]}\\n')\n",
    "            for param_e in param:\n",
    "                hex_conv = convert_and_concatenate(param_e)\n",
    "                segments = [hex_conv[i:i+8] for i in range(0, len(hex_conv), 8)]\n",
    "                segments.reverse()\n",
    "                for segment in segments:\n",
    "                    f.write(f'0x{segment}\\n')\n",
    "            f.write(f'\\n')\n",
    "    return 0\n",
    "\n",
    "# Gọi hàm để lưu thông số mô hình\n",
    "a = save_model_parameters_to_txt(model_bnn, 'bnn_model_parameters.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Validation Accuracy: 91.52%1\n",
      "Epoch [2/2], Validation Accuracy: 91.63%0\n",
      "Test Accuracy: 91.51%\n"
     ]
    }
   ],
   "source": [
    "class Net_fp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_fp, self).__init__()\n",
    "        self.linear1 = nn.Linear(13, 128, bias = False)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(128, 128, bias = False)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.linear3 = nn.Linear(128, 128, bias = False)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.act3 = nn.ReLU()\n",
    "\n",
    "        self.linear4 = nn.Linear(128, 3, bias = False)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "        # x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "\n",
    "        x = self.linear4(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_fp = Net_fp().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_fp.parameters(), 0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model_fp.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_fp(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # model_ter1.set_weights_and_biases()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}', end='\\r')\n",
    "    \n",
    "    model_fp.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_fp(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Final evaluation on the test set\n",
    "model_fp.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_fp(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "torch.save(model_fp.state_dict(), 'saved_best_model_fp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_fp_parameters_to_txt(model, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.write(f'{name}\\n')\n",
    "            if('linear' in name and 'weight'in name):\n",
    "                f.write(f'input_channel: {param.shape[1]}\\n')\n",
    "                f.write(f'output_channel: {param.shape[0]}\\n')\n",
    "            f.write(f'{param}\\n')\n",
    "            f.write(f'\\n')\n",
    "    return 0\n",
    "\n",
    "# Gọi hàm để lưu thông số mô hình\n",
    "a = save_model_fp_parameters_to_txt(model_fp, 'fp_model_parameters.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ternary(x: torch.Tensor, delta: float):\n",
    "    return (x >= delta).float() - (x <= -delta).float()\n",
    "\n",
    "class _ternary_py(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def ternary_backward(grad_output: torch.Tensor, x: torch.Tensor, delta: float, order: int, threshold: float):\n",
    "        scale = 2 * delta\n",
    "        assert threshold <= scale\n",
    "        tmp = torch.zeros_like(grad_output)\n",
    "        tmp += ((x >= -threshold) & (x <= threshold)).float() * order * \\\n",
    "               (torch.fmod(x / delta + 3, 2) - 1).abs().pow(order - 1)\n",
    "        return grad_output * tmp\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, *inputs) -> torch.Tensor:\n",
    "        input_f, running_delta, delta, momentum, training, ctx.order = inputs\n",
    "        if momentum > 0:\n",
    "            if training:\n",
    "                ctx.delta = input_f.norm(1).item() * (delta / input_f.numel())  # = delta * |input_f|_1 / n\n",
    "                running_delta.data = momentum * ctx.delta + (1.0 - momentum) * running_delta.data\n",
    "            else:\n",
    "                ctx.delta = running_delta.data.item()\n",
    "        else:\n",
    "            ctx.delta = delta\n",
    "        # input_t = _ternary(input_f, ctx.delta) * (2 * ctx.delta)\n",
    "        input_t = _ternary(input_f, ctx.delta)\n",
    "        ctx.save_for_backward(input_f)\n",
    "        return input_t\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grad_outputs):\n",
    "        grad_output, = grad_outputs\n",
    "        input_f, = ctx.saved_tensors\n",
    "        grad_input = _ternary_py.ternary_backward(grad_output, input_f, ctx.delta, ctx.order, 2. * ctx.delta)\n",
    "        return grad_input, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "def ternary(input_f: torch.Tensor, running_delta, delta, momentum, training, order):\n",
    "    return _ternary_py.apply(input_f, running_delta, delta, momentum, training, order)\n",
    "\n",
    "\n",
    "class Ternary(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ternary, self).__init__()\n",
    "        config = {}\n",
    "        self.config = config\n",
    "        self.delta = config.setdefault(\"delta\", 0.5)\n",
    "        self.momentum = config.setdefault(\"momentum\", 0.01)\n",
    "        self.track_running_stats = config.setdefault(\"track_running_stats\", True)\n",
    "        self.order = config.setdefault('order', 2)\n",
    "        # self.use_scale = config.setdefault('use_scale', True)\n",
    "        assert self.momentum <= 1 and self.order > 0 and self.delta > 0\n",
    "        self.register_buffer(\"running_delta\", torch.zeros(1))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.momentum > 0:\n",
    "            self.running_delta.fill_(self.delta * 0.7979)\n",
    "        else:\n",
    "            self.running_delta.fill_(self.delta)\n",
    "\n",
    "    def forward(self, input_f):\n",
    "        return ternary(input_f, self.running_delta, self.delta, self.momentum,\n",
    "                       self.training and self.track_running_stats, self.order)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \", \".join([\"{}={}\".format(k, v) for k, v in self.config.items()])\n",
    "class QLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.input_quantizer = Ternary()\n",
    "        self.weight_quantizer = Ternary()\n",
    "\n",
    "    def forward(self, input_f):\n",
    "        input_t = self.input_quantizer(input_f)\n",
    "        weight_b = self.weight_quantizer(self.weight)\n",
    "        out = F.linear(input_t, weight_b, self.bias)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Validation Accuracy: 84.68%2\n",
      "Epoch [2/4], Validation Accuracy: 91.85%8\n",
      "Epoch [3/4], Validation Accuracy: 91.85%4\n",
      "Epoch [4/4], Validation Accuracy: 91.85%9\n",
      "Test Accuracy: 91.74%\n"
     ]
    }
   ],
   "source": [
    "class Net_tnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_tnn, self).__init__()\n",
    "\n",
    "        self.linear1 = QLinear(13, 128, bias = False)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.i1 = nn.Identity()\n",
    "\n",
    "        self.linear2 = QLinear(128, 128, bias = False)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.i2 = nn.Identity()\n",
    "\n",
    "        self.linear3 = QLinear(128, 128, bias = False)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        # self.i3 = nn.Identity()\n",
    "\n",
    "        self.linear4 = QLinear(128, 3, bias = False)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear1(x)\n",
    "        # x = self.bn1(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear2(x)\n",
    "        # x = self.bn2(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear3(x)\n",
    "        # x = self.bn3(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_tnn = Net_tnn().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_tnn.parameters(), 0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model_tnn.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_tnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # model_ter1.set_weights_and_biases()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}', end='\\r')\n",
    "    \n",
    "    model_tnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_tnn(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Final evaluation on the test set\n",
    "model_tnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_tnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "torch.save(model_tnn.state_dict(), 'saved_best_model_tnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight\n",
      "linear2.weight\n",
      "linear3.weight\n",
      "linear4.weight\n"
     ]
    }
   ],
   "source": [
    "def convert_and_concatenate_tnn(arr):\n",
    "    arr = torch.flip(arr, dims=[0])\n",
    "    # Chuyển đổi -1 thành 1 và 1 thành 0\n",
    "    converted_bit0_arr = [1 if x == -1 else 0 for x in arr]\n",
    "    converted_bit1_arr = [1 if x == 1 else 0 for x in arr]\n",
    "    concatenated_bit0_str = ''.join(map(str, converted_bit0_arr))\n",
    "    concatenated_bit1_str = ''.join(map(str, converted_bit1_arr))\n",
    "\n",
    "\n",
    "    current_length = np.max([len(concatenated_bit0_str),len(concatenated_bit0_str)])\n",
    "    total_length = (np.ceil(current_length/32)*32).astype(int)\n",
    "    if current_length < total_length:\n",
    "        padding_length0 = int(total_length - len(concatenated_bit0_str))\n",
    "        padding_length1 = int(total_length - len(concatenated_bit1_str))\n",
    "        concatenated_bit0_str = '0' * padding_length0 + concatenated_bit0_str\n",
    "        concatenated_bit1_str = '0' * padding_length1 + concatenated_bit1_str\n",
    "\n",
    "    # Chuyển chuỗi thành số nhị phân và sau đó thành số hex\n",
    "    hex_value_bit0 = hex(int(concatenated_bit0_str, 2))[2:]  # Bỏ tiền tố '0x'\n",
    "    hex_value_bit1 = hex(int(concatenated_bit1_str, 2))[2:]  # Bỏ tiền tố '0x'\n",
    "    # Đảm bảo chuỗi hex đủ độ dài cần thiết\n",
    "    if(len(hex_value_bit0)>len(hex_value_bit1)):\n",
    "        hex_value_bit1 = '0' * (len(hex_value_bit0)-len(hex_value_bit1)) + hex_value_bit1\n",
    "    elif(len(hex_value_bit0)<len(hex_value_bit1)):\n",
    "        hex_value_bit0 = '0' * (len(hex_value_bit1)-len(hex_value_bit0)) + hex_value_bit0\n",
    "\n",
    "    hex_length = total_length // 4  # 1 hex digit = 4 bits\n",
    "    if len(hex_value_bit0) < hex_length:\n",
    "        hex_value_bit0 = '0' * (hex_length - len(hex_value_bit0)) + hex_value_bit0\n",
    "        hex_value_bit1 = '0' * (hex_length - len(hex_value_bit1)) + hex_value_bit1\n",
    "    return hex_value_bit0, hex_value_bit1\n",
    "\n",
    "def save_tnn_model_parameters_to_txt(model, file_path):\n",
    "    input_thres = []\n",
    "    weight_thres = []\n",
    "    for name, module in model.named_modules():        \n",
    "        if 'input_quantizer' in name:\n",
    "            input_thres = np.append(input_thres, module.running_delta.item())\n",
    "        if 'weight_quantizer' in name:\n",
    "            weight_thres = np.append(weight_thres, module.running_delta.item())\n",
    "    # input_thres = np.append(input_thres, 0)\n",
    "    cnt=0\n",
    "    with open(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.write(f'{name}\\n')\n",
    "            f.write(f'input_channel: {param.shape[1]}\\n')\n",
    "            f.write(f'output_channel: {param.shape[0]}\\n')\n",
    "            f.write(f'input_thres: {input_thres[cnt]}\\n')\n",
    "\n",
    "            param = _ternary(param, weight_thres[cnt])\n",
    "            print(name)\n",
    "            for param_e in param:\n",
    "                hex_conv_bit0, hex_conv_bit1 = convert_and_concatenate_tnn(param_e)\n",
    "                segments0 = [hex_conv_bit0[i:i+8] for i in range(0, len(hex_conv_bit0), 8)]\n",
    "                segments1 = [hex_conv_bit1[i:i+8] for i in range(0, len(hex_conv_bit1), 8)]\n",
    "                segments0.reverse()\n",
    "                segments1.reverse()\n",
    "                for j in range (len(segments0)):\n",
    "                    f.write(f'0x{segments0[j]}\\n')\n",
    "                    f.write(f'0x{segments1[j]}\\n')\n",
    "            f.write(f'\\n')\n",
    "            cnt+=1\n",
    "    return 0\n",
    "\n",
    "# Gọi hàm để lưu thông số mô hình\n",
    "a = save_tnn_model_parameters_to_txt(model_tnn, 'tnn_model_parameters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net_tnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_tnn, self).__init__()\n",
    "\n",
    "        self.linear1 = QLinear(13, 128, bias = False)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.i1 = nn.Identity()\n",
    "\n",
    "        self.linear2 = QLinear(128, 128, bias = False)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.i2 = nn.Identity()\n",
    "\n",
    "        self.linear3 = QLinear(128, 128, bias = False)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        # self.i3 = nn.Identity()\n",
    "\n",
    "        self.linear4 = QLinear(128, 3, bias = False)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear1(x)\n",
    "        print(\"linear1: \")\n",
    "        print(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear2(x)\n",
    "        print(\"linear2: \")\n",
    "        print(x)\n",
    "        # x = self.bn2(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear3(x)\n",
    "        print(\"linear3: \")\n",
    "        print(x)\n",
    "        # x = self.bn3(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear4(x)\n",
    "        print(\"linear4: \")\n",
    "        print(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "model_tnn_test = Net_tnn().to(device)\n",
    "checkpoint = torch.load('saved_best_model_tnn.pt')\n",
    "model_tnn_test.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1: \n",
      "tensor([[-3.,  0.,  3.,  2., -4.,  0.,  1.,  1.,  0.,  1., -3., -1.,  0.,  1.,\n",
      "          1.,  1., -3.,  1.,  1.,  1.,  3.,  0., -3.,  1.,  1., -1., -1.,  0.,\n",
      "          0., -1., -1.,  1., -1.,  5., -2.,  1., -3., -2.,  1.,  1., -1.,  4.,\n",
      "          1., -2., -1., -2.,  1.,  2.,  1., -2.,  1.,  0.,  0.,  1.,  1., -1.,\n",
      "          0.,  2.,  0., -1.,  2.,  2.,  0., -1., -2., -3., -3., -3., -3.,  1.,\n",
      "         -4.,  1., -3., -2., -1.,  1.,  0.,  3., -1.,  1.,  2.,  0., -2., -3.,\n",
      "          0.,  2., -1.,  1., -2., -2.,  2.,  2., -1., -2.,  1.,  0.,  2.,  4.,\n",
      "          5., -3., -2., -1.,  1., -1., -4.,  0.,  2., -2.,  1., -1.,  0., -1.,\n",
      "          0.,  1.,  3.,  1.,  1.,  3.,  3., -1.,  1.,  2.,  3., -2.,  0.,  2.,\n",
      "          0., -2.]], device='cuda:0')\n",
      "linear2: \n",
      "tensor([[ 12.,   6., -10., -14.,  -5.,   8.,  10.,   1.,  31.,  12.,  10.,  -5.,\n",
      "          -2.,  11., -12., -24.,  -1.,  -2.,  11.,  -4.,  12.,   4.,   2., -14.,\n",
      "          -5.,  -2.,  -3.,   1.,   7., -15.,   5.,  -4.,  -4.,   9.,   5.,   2.,\n",
      "           8., -11.,  -5., -10.,  -2.,   5.,   5.,  -5., -17.,   3.,  11.,  -4.,\n",
      "         -11.,   3., -10.,   9.,   1.,  -5.,  14.,  -3.,  -5.,   0.,  24.,   4.,\n",
      "           6.,  14.,   9.,  -2.,   7.,   0.,  11.,   0.,   3.,  22., -17., -16.,\n",
      "          14.,   8., -14.,  -2., -12.,  -8.,   3., -13., -23.,   5., -15.,  -2.,\n",
      "           6.,  14., -13.,  27.,   3.,   8., -13.,   6.,  10.,  -7.,   3.,  11.,\n",
      "          -5., -18.,   1.,   9.,  12., -11., -10.,  -8.,  -3., -18., -11.,  -7.,\n",
      "          -8.,   8.,   8.,  16., -13.,  -2.,   8., -18.,  -8.,  -3.,  -2., -19.,\n",
      "          11.,  -2.,  13., -21., -10.,  -4.,  11.,  15.]], device='cuda:0')\n",
      "linear3: \n",
      "tensor([[  1., -11.,  13.,  -5.,   0.,  10.,   6.,   5.,  -1.,  -8.,  -1.,   0.,\n",
      "           0.,  -6.,   1.,  -1.,   0.,   2.,  -7.,   2.,  -7.,  10.,  19.,   1.,\n",
      "           5., -16.,  -1.,  -4.,   3., -20.,  -1.,   8.,  17.,  11.,   2.,  13.,\n",
      "           3.,  -5.,   3.,   6.,   2.,  -1.,  -4.,   3.,  12.,  14.,  16.,  -4.,\n",
      "          -2.,  -4., -10.,  14.,   7.,  -2.,  -4.,   4.,   5.,   2.,  13.,  11.,\n",
      "          -2.,  -5.,   6.,  -6.,  11.,  -7.,  -8.,  12.,  14.,   3.,  -6.,  12.,\n",
      "          16., -12.,   3.,   0.,  -1.,  -4., -15.,  -4.,  10.,  -5., -12.,  13.,\n",
      "           1.,   0.,  -2.,   3., -10.,   5.,   7.,  16.,   9.,  12.,  -1.,   9.,\n",
      "         -15.,  18.,   1.,  -9.,   0.,   7.,  -4.,   9.,  -5.,   3.,  -1., -12.,\n",
      "           1.,  11., -18.,  -8.,   5.,   4.,   1.,  12.,  -3.,  11.,  -7.,  -1.,\n",
      "           8.,   1.,  -6.,  -5.,  12.,  -5., -19.,   1.]], device='cuda:0')\n",
      "linear4: \n",
      "tensor([[-18.,  -9.,  17.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "model_tnn_test.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test = torch.tensor([[0.0000,  0.0000,  0.0000,  0.0000, -0.6556,  0.9844,  0.2236, -1.4968, -1.4968, -0.9711, -0.1279,  0.2186,  0.2208]]).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model_tnn_test(test)\n",
    "\n",
    "# test_accuracy = 100 * correct / total\n",
    "# print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.3157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TBN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.input_quantizer = Ternary()\n",
    "        self.weight_quantizer = BinaryActivation()\n",
    "\n",
    "    def forward(self, input_f):\n",
    "        input_t = self.input_quantizer(input_f)\n",
    "        weight_b = self.weight_quantizer(self.weight)\n",
    "        out = F.linear(input_t, weight_b, self.bias)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Validation Accuracy: 86.25%1\n",
      "Epoch [2/4], Validation Accuracy: 88.99%8\n",
      "Epoch [3/4], Validation Accuracy: 92.04%7\n",
      "Epoch [4/4], Validation Accuracy: 92.04%3\n",
      "Test Accuracy: 91.98%\n"
     ]
    }
   ],
   "source": [
    "class Net_tbn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_tbn, self).__init__()\n",
    "\n",
    "        self.linear1 = QLinear(13, 128, bias = False)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.i1 = nn.Identity()\n",
    "\n",
    "        self.linear2 = QLinear(128, 128, bias = False)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.i2 = nn.Identity()\n",
    "\n",
    "        self.linear3 = QLinear(128, 128, bias = False)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        # self.i3 = nn.Identity()\n",
    "\n",
    "        self.linear4 = QLinear(128, 3, bias = False)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear1(x)\n",
    "        # x = self.bn1(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear2(x)\n",
    "        # x = self.bn2(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear3(x)\n",
    "        # x = self.bn3(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_tbn = Net_tbn().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_tbn.parameters(), 0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model_tbn.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_tbn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # model_ter1.set_weights_and_biases()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}', end='\\r')\n",
    "    \n",
    "    model_tbn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_tbn(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Final evaluation on the test set\n",
    "model_tbn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_tbn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "torch.save(model_tbn.state_dict(), 'saved_best_model_tbn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight\n",
      "linear2.weight\n",
      "linear3.weight\n",
      "linear4.weight\n"
     ]
    }
   ],
   "source": [
    "def _binary(x: torch.Tensor):\n",
    "    return (x >= 0).float() - (x < 0).float()\n",
    "\n",
    "def convert_and_concatenate_tbn(arr):\n",
    "    # Chuyển đổi -1 thành 1 và 1 thành 0\n",
    "    arr = torch.flip(arr, dims=[0])\n",
    "    converted_arr = [1 if x == -1 else 0 for x in arr]\n",
    "    # Ghép các phần tử lại thành một chuỗi\n",
    "    concatenated_str = ''.join(map(str, converted_arr))\n",
    "\n",
    "    current_length = len(concatenated_str)\n",
    "    total_length = (np.ceil(current_length/32)*32).astype(int)\n",
    "    if current_length < total_length:\n",
    "        padding_length = int(total_length - current_length)\n",
    "        concatenated_str = '0' * padding_length + concatenated_str\n",
    "    # Chuyển chuỗi thành số nhị phân và sau đó thành số hex\n",
    "    hex_value = hex(int(concatenated_str, 2))[2:]  # Bỏ tiền tố '0x'\n",
    "\n",
    "    # Đảm bảo chuỗi hex đủ độ dài cần thiết\n",
    "    hex_length = total_length // 4  # 1 hex digit = 4 bits\n",
    "    if len(hex_value) < hex_length:\n",
    "        hex_value = '0' * (hex_length - len(hex_value)) + hex_value\n",
    "    return hex_value\n",
    "\n",
    "def save_tbn_model_parameters_to_txt(model, file_path):\n",
    "    input_thres = []\n",
    "    for name, module in model.named_modules():        \n",
    "        if 'input_quantizer' in name:\n",
    "            input_thres = np.append(input_thres, module.running_delta.item())\n",
    "    # input_thres = np.append(input_thres, 0)\n",
    "    cnt=0\n",
    "    with open(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.write(f'{name}\\n')\n",
    "            f.write(f'input_channel: {param.shape[1]}\\n')\n",
    "            f.write(f'output_channel: {param.shape[0]}\\n')\n",
    "            f.write(f'input_thres: {input_thres[cnt]}\\n')\n",
    "\n",
    "            param = _binary(param)\n",
    "            print(name)\n",
    "            for param_e in param:\n",
    "                hex_conv_bit = convert_and_concatenate_tbn(param_e)\n",
    "                segments = [hex_conv_bit[i:i+8] for i in range(0, len(hex_conv_bit), 8)]\n",
    "                segments.reverse()\n",
    "                for j in range (len(segments)):\n",
    "                    f.write(f'0x{segments[j]}\\n')\n",
    "            f.write(f'\\n')\n",
    "            cnt+=1\n",
    "    return 0\n",
    "\n",
    "# Gọi hàm để lưu thông số mô hình\n",
    "a = save_tbn_model_parameters_to_txt(model_tbn, 'tbn_model_parameters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "          1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "         -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "          1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.,\n",
       "          1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "         -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
       "         -1., -1.],\n",
       "        [-1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "          1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.,\n",
       "          1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "         -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,\n",
       "         -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "          1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "         -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "         -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "         -1.,  1.],\n",
       "        [ 1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "          1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "          1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "          1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "         -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "          1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "         -1.,  1.]], device='cuda:0')"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.input_quantizer = Ternary()\n",
    "        self.weight_quantizer = BinaryActivation()\n",
    "\n",
    "    def forward(self, input_f):\n",
    "        input_t = self.input_quantizer(input_f)\n",
    "        weight_b = self.weight_quantizer(self.weight)\n",
    "        out = F.linear(input_t, weight_b, self.bias)\n",
    "        return out\n",
    "\n",
    "class Net_tbn_test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_tbn_test, self).__init__()\n",
    "\n",
    "        self.linear1 = QLinear(13, 128, bias = False)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.i1 = nn.Identity()\n",
    "\n",
    "        self.linear2 = QLinear(128, 128, bias = False)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.i2 = nn.Identity()\n",
    "\n",
    "        self.linear3 = QLinear(128, 128, bias = False)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        # self.i3 = nn.Identity()\n",
    "\n",
    "        self.linear4 = QLinear(128, 3, bias = False)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear1(x)\n",
    "        print(\"linear1: \")\n",
    "        print(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear2(x)\n",
    "        print(\"linear2: \")\n",
    "        print(x)\n",
    "        # x = self.bn2(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear3(x)\n",
    "        print(\"linear3: \")\n",
    "        print(x)\n",
    "        # x = self.bn3(x)\n",
    "\n",
    "        # x = self.input_quantizer(x)\n",
    "        x = self.linear4(x)\n",
    "        print(\"linear4: \")\n",
    "        print(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "model_tbn_test = Net_tbn_test().to(device)\n",
    "checkpoint = torch.load('saved_best_model_tbn.pt')\n",
    "model_tbn_test.load_state_dict(checkpoint)\n",
    "model_tbn_test.linear1.state_dict()['weight'].copy_(_binary(model_tbn_test.linear1.state_dict()['weight']))\n",
    "model_tbn_test.linear2.state_dict()['weight'].copy_(_binary(model_tbn_test.linear2.state_dict()['weight']))\n",
    "model_tbn_test.linear3.state_dict()['weight'].copy_(_binary(model_tbn_test.linear3.state_dict()['weight']))\n",
    "model_tbn_test.linear4.state_dict()['weight'].copy_(_binary(model_tbn_test.linear4.state_dict()['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1: \n",
      "tensor([[-1., -3.,  1., -1.,  3., -1., -3.,  3.,  3.,  1.,  1., -3.,  3., -3.,\n",
      "          3.,  1.,  1.,  3.,  3., -1., -1., -1., -1.,  1., -3.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1., -1.,  3.,  5., -5., -1.,  3.,  1., -1., -1.,  5., -5.,\n",
      "          1., -5.,  1., -3., -1., -3.,  5.,  1., -1., -1., -1.,  1., -3., -5.,\n",
      "          1., -3., -3., -1.,  5., -3., -5.,  1., -1.,  3., -1., -1., -3.,  3.,\n",
      "         -1.,  5., -1., -1., -5., -1., -3.,  1.,  5., -1.,  5.,  3.,  3., -1.,\n",
      "          1.,  3., -1., -3.,  1.,  5.,  5.,  1.,  3.,  3.,  1.,  3.,  1.,  3.,\n",
      "         -1., -1.,  1., -3.,  3., -5., -1.,  1., -3., -1.,  1.,  1.,  5.,  1.,\n",
      "         -3.,  5.,  3., -1., -5., -1., -3., -1.,  5.,  3., -1., -1.,  1.,  1.,\n",
      "         -3.,  1.]], device='cuda:0')\n",
      "linear2: \n",
      "tensor([[ -4., -28., -30.,  -2.,   4.,  48.,  -2., -14.,  -4., -16.,   8.,  16.,\n",
      "           6.,   4.,   8.,  28.,  -8., -16.,   6.,  -6.,  20.,  26.,   4., -30.,\n",
      "          20., -10., -16.,   6.,   4., -42.,  18., -34., -10., -12.,   2.,   4.,\n",
      "           2., -18.,  18., -16.,  14.,   2.,  28.,  18.,  -8.,   6., -16.,  18.,\n",
      "          20.,  22., -10.,  12., -16.,   4.,  14., -10., -16.,  -8., -34.,  -8.,\n",
      "          -2.,  -2.,  -6.,  28.,   6.,  -8.,  -4.,  26.,  20.,  28.,  28.,  12.,\n",
      "          14.,   6.,  12., -10.,  18., -10., -12., -16.,   0., -42., -24.,  16.,\n",
      "          12., -12.,  26.,  12.,  22.,  10.,  22., -28., -24.,  -4.,  18.,  22.,\n",
      "         -10.,   2., -22., -34.,  10.,  18.,   4., -32.,   2.,   6., -12., -12.,\n",
      "         -20.,   0.,  -4., -10.,  22.,  32.,   8., -20., -22., -22., -20.,   6.,\n",
      "          24.,  10.,   4., -22., -28., -28.,  24.,  18.]], device='cuda:0')\n",
      "linear3: \n",
      "tensor([[ -2.,   0.,  -2.,  18.,   2.,   2.,   4.,   0.,  -4.,  10., -32.,  -6.,\n",
      "         -18.,  -2.,   0., -10.,   2., -10., -28., -10.,  18.,  24.,   4., -12.,\n",
      "          12.,   0.,  16.,   6.,  -4.,  -2.,  18.,   6.,  -8.,  10.,  -4.,  18.,\n",
      "          10.,  -8.,   4.,  -8.,  -6., -14.,  10.,   6.,   2.,  20.,   4.,   4.,\n",
      "          22.,  24.,  -6.,  16., -10., -14.,   0.,   2.,   0.,   0.,  22., -30.,\n",
      "          -8.,   2., -18.,   2.,  -2.,  16.,  -8.,  -6., -22.,  28.,   8.,  12.,\n",
      "          20.,   6.,  -4., -16., -14.,  -4.,  -6.,  20.,   8.,  12., -10.,  12.,\n",
      "          12.,  16., -18., -14., -24.,  -4., -10.,   6.,   8., -14.,  10.,   0.,\n",
      "          -4.,   6., -18.,  -4., -12.,  -2.,  -2.,  -8., -20.,   0.,   6.,   6.,\n",
      "           8.,  -8.,  16.,   4.,   4.,   6., -12.,   8.,  -2.,   2.,  -4.,   6.,\n",
      "          16., -14.,   2., -28.,  -8.,  -8., -12.,  -2.]], device='cuda:0')\n",
      "linear4: \n",
      "tensor([[ -1., -17.,  45.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "model_tbn_test.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test = torch.tensor([[0.0000,  0.0000,  0.0000,  0.0000, -0.6556,  0.9844,  0.2236, -1.4968, -1.4968, -0.9711, -0.1279,  0.2186,  0.2208]]).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model_tbn_test(test)\n",
    "\n",
    "# test_accuracy = 100 * correct / total\n",
    "# print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GENERATE TESTCASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12712/3797725696.py:12: RuntimeWarning: invalid value encountered in log\n",
      "  x[:,i] = np.where(x[:,i] > 0, np.log(x[:,i]), 0)\n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([df_bot_dos, df_bot_ddos], ignore_index=True)\n",
    "\n",
    "x = df_combined.loc[:, df_combined.columns != 'category']\n",
    "# x = (x-x.min())/(x.max()-x.min())\n",
    "\n",
    "df_combined.category = pd.factorize(df_combined.category)[0]\n",
    "y = df_combined['category']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "for i in [0,1,2,3,7,8]:\n",
    "    x[:,i] = np.where(x[:,i] > 0, np.log(x[:,i]), 0)\n",
    "    \n",
    "x_label_data = torch.tensor(x, dtype=torch.float).to(device)\n",
    "y_label_data = torch.tensor(y, dtype=torch.long).to(device)\n",
    "\n",
    "dataset = TensorDataset(x_label_data, y_label_data)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.275 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8192\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84000"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tbn_model_parameters_to_txt(model, file_path):\n",
    "    input_thres = []\n",
    "    for name, module in model.named_modules():        \n",
    "        if 'input_quantizer' in name:\n",
    "            input_thres = np.append(input_thres, module.running_delta.item())\n",
    "    # input_thres = np.append(input_thres, 0)\n",
    "    cnt=0\n",
    "    with open(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.write(f'{name}\\n')\n",
    "            f.write(f'input_channel: {param.shape[1]}\\n')\n",
    "            f.write(f'output_channel: {param.shape[0]}\\n')\n",
    "            f.write(f'input_thres: {input_thres[cnt]}\\n')\n",
    "\n",
    "            param = _binary(param)\n",
    "            print(name)\n",
    "            for param_e in param:\n",
    "                hex_conv_bit = convert_and_concatenate_tbn(param_e)\n",
    "                segments = [hex_conv_bit[i:i+8] for i in range(0, len(hex_conv_bit), 8)]\n",
    "                segments.reverse()\n",
    "                for j in range (len(segments)):\n",
    "                    f.write(f'0x{segments[j]}\\n')\n",
    "            f.write(f'\\n')\n",
    "            cnt+=1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'testcase.txt'\n",
    "with open(file_path, 'w') as f:\n",
    "    for images, labels in test_loader:\n",
    "        f.write(f'testcase: {tc}\\n')\n",
    "        f.write(f'data: {images[0]}\\n'.replace(\" \", \"\"))\n",
    "        f.write(f'label: {labels[0].cpu().numpy()}\\n')\n",
    "        f.write(f'\\n')\n",
    "        tc +=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human_action",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
