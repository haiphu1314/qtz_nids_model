{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usami/miniconda3/envs/human_action/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/usami/miniconda3/envs/human_action/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c107WarningC1ENS_7variantIJNS0_11UserWarningENS0_18DeprecationWarningEEEERKNS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# modified from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import models\n",
    "\n",
    "from qconv import QConv2d\n",
    "from qlinear import QLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "df_unsw_normal = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/dataset/train/unsw_normal.csv')\n",
    "df_bot_dos = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/dataset/train/bot_iot_dos.csv')\n",
    "df_bot_ddos = pd.read_csv('/home/usami/Protocol-Based-Deep-Intrusion-Detection-for-DoS-Normal-and-DDoS-Attacks/normal_ddos_dos_classification/dataset/train/bot_iot_ddos.csv')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1202194/4249798583.py:12: RuntimeWarning: invalid value encountered in log\n",
      "  x[:,i] = np.where(x[:,i] > 0, np.log(x[:,i]), 0)\n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([df_unsw_normal, df_bot_dos, df_bot_ddos], ignore_index=True)\n",
    "\n",
    "x = df_combined.loc[:, df_combined.columns != 'category']\n",
    "# x = (x-x.min())/(x.max()-x.min())\n",
    "\n",
    "df_combined.category = pd.factorize(df_combined.category)[0]\n",
    "y = df_combined['category']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "for i in [0,1,2,3,7,8]:\n",
    "    x[:,i] = np.where(x[:,i] > 0, np.log(x[:,i]), 0)\n",
    "    \n",
    "x_label_data = torch.tensor(x, dtype=torch.float).to(device)\n",
    "y_label_data = torch.tensor(y, dtype=torch.long).to(device)\n",
    "\n",
    "dataset = TensorDataset(x_label_data, y_label_data)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8192\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binary_weight(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, weight_f):\n",
    "        scale = weight_f.abs().sum(dim=list(range(1, weight_f.ndim)), keepdim=True) / weight_f[0].numel()\n",
    "        weight_b = weight_f.sign() * scale\n",
    "        return weight_b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grad_outputs):\n",
    "        return grad_outputs\n",
    "\n",
    "\n",
    "class BinaryWeight(nn.Module):\n",
    "    def __init__(self, config: dict, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, weight_f):\n",
    "        weight_b = binary_weight.apply(weight_f)\n",
    "        return weight_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Validation Accuracy: 91.70%7\n",
      "Epoch [2/2], Validation Accuracy: 91.86%3\n",
      "Test Accuracy: 91.87%\n"
     ]
    }
   ],
   "source": [
    "class Net_tea(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_tea, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(13, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.i1 = nn.Identity()\n",
    "\n",
    "        self.linear2 = QLinear(128, 128, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.i2 = nn.Identity()\n",
    "\n",
    "        self.linear3 = QLinear(128, 128, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        # self.i3 = nn.Identity()\n",
    "\n",
    "        self.linear4 = nn.Linear(128, 3)\n",
    "        self.act4 = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.net(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        # x = self.i1(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)\n",
    "        # x = self.i2(x)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "        x = self.bn3(x)\n",
    "        # x = self.i3(x)\n",
    "\n",
    "        x = self.linear4(x)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ter1 = Net_tea().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_ter1.parameters(), 0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model_ter1.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_ter1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # model_ter1.set_weights_and_biases()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}', end='\\r')\n",
    "    \n",
    "    model_ter1.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ter1(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Final evaluation on the test set\n",
    "model_ter1.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model_ter1(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "torch.save(model_ter1.state_dict(), 'saved_best_model_ter.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human_action",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
